[
  {
    "objectID": "calendar.html",
    "href": "calendar.html",
    "title": "Calendar",
    "section": "",
    "text": "This is an example of embedding a widget with multiple calendars. This might be useful if you want to have different calendars for assignments, exams, instructor office hours, GSI office hours, etc.",
    "crumbs": [
      "Calendar"
    ]
  },
  {
    "objectID": "calendar.html#course-calendar",
    "href": "calendar.html#course-calendar",
    "title": "Calendar",
    "section": "",
    "text": "This is an example of embedding a widget with multiple calendars. This might be useful if you want to have different calendars for assignments, exams, instructor office hours, GSI office hours, etc.",
    "crumbs": [
      "Calendar"
    ]
  },
  {
    "objectID": "staff.html",
    "href": "staff.html",
    "title": "Course Staff",
    "section": "",
    "text": "[UNDER CONSTRUCTION]\nOffice hours are subject to change.\n\n\n\nInstructor:: Shobhana Murali Stoyanov   shobhana@berkeley.edu Office hours:  - Mondays 10 am - 12 pm, Evans 333  pronouns: she/her\n\n\nGSI: Chuao Dong   chuaodong@berkeley.edu Office hours: TBD  pronouns: she/her\n\n\nGSI: Thomas Lee   tholee@berkeley.edu Office hours: TBD  pronouns: he/him\n\n\nGSI: Tobias Roemer   tobias_roemer@berkeley.edu Office hours: TBD  pronouns: he/him\n\n\nTutor: Neha Suresh   neha_suresh@berkeley.edu pronouns: she/her\n\n\n\n\n\nReader: Jenny Gao    pronouns: she/her\n\n\nReader: Aurora Shi    pronouns: she/her",
    "crumbs": [
      "Staff"
    ]
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "This work is licensed under a Creative Commons Attribution 4.0 International License.",
    "crumbs": [
      "License"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "[UNDER CONSTRUCTION]",
    "crumbs": [
      "Datasets"
    ]
  },
  {
    "objectID": "data.html#data-1",
    "href": "data.html#data-1",
    "title": "Data",
    "section": "Data 1",
    "text": "Data 1",
    "crumbs": [
      "Datasets"
    ]
  },
  {
    "objectID": "data.html#data-2",
    "href": "data.html#data-2",
    "title": "Data",
    "section": "Data 2",
    "text": "Data 2",
    "crumbs": [
      "Datasets"
    ]
  },
  {
    "objectID": "lectures/lecture-1.html",
    "href": "lectures/lecture-1.html",
    "title": "Syllabus, Course Overview, and Diagnostic Test",
    "section": "",
    "text": "The plan for today is to review the syllabus, read the overview of the course below, and work on the diagnostic test. Please give yourself about 30 minutes to complete it. Of course, if you take longer we will not know, but you should think about why it is taking you longer, and review those topics that you think you might have forgotten.\nOnce you are done with the test, please upload it to Gradescope. Since this does not count towards your course grade, it is due on Thursday night and there is no extension possible. If you turn it in, you get \\(0.25\\%\\) extra credit towards your final course average. If you don’t turn it in, it’s okay, these things happen. Don’t stress.",
    "crumbs": [
      "Lecture 1: Syllabus & Diagnostic Test"
    ]
  },
  {
    "objectID": "lectures/lecture-1.html#course-overview",
    "href": "lectures/lecture-1.html#course-overview",
    "title": "Syllabus, Course Overview, and Diagnostic Test",
    "section": "Course Overview",
    "text": "Course Overview\n\nProbability vs Statistics\n\n\n\n\n\nWhen we study probability, we have some data generating process (perhaps we are sampling from a known distribution, or we are sampling at random from a box with \\(N\\) items etc), and we want to know something about the random sample that we generate, and its properties.\nNow, when we study inference, we are given the sample, and we want to know more about the process that generated the data. That is, we want to infer something about the population, given the data that we observe.\n\n\nEstimation\n\nSimple Random Sampling\n\nWe might make no distributional assumptions about the population, and then try to estimate the population mean and variance and other parameters. This is the material we will study in Chapter 7, estimates from survey sampling. In this chapter we treat the estimate as a random variable that has a sampling distribution. This just means that each time we take a sample (of some fixed size) we get a different observed value of our random variable. All such possible values give us a distribution of the random variable (for example, the sample mean) which is called its sampling distribution.\nWhile investigating these estimates, we will talk about the concepts of bias, standard error, and mean squared error, confidence intervals, and how we apply the central limit theorem. Here are two visualizations of the CLT, with the top row showing the sampling distribution of the sample mean of random samples of \\(Unif(0,1)\\) random variables for various \\(n\\). The bottom row does the same for a \\(Gamma(2,1)\\) distribution. You can see how even though we begin with distributions that are very far from a normal distribution, for larger \\(n\\), the distribution of the sample mean is approximately normal!\n\n\n\n\n\n\n\n\n\n\n\nResampling methods: We will use the bootstrap to estimate confidence bounds for our parameters. When possible, we will compare these confidence intervals to the ones obtained by classical methods.\n\n\n\nEstimating distributional parameters\n\nOn the other hand, depending on what we know about the population, we might build models with distributional assumptions: for example, the number of goals in the soccer World Cup could be modeled using the Poisson distribution.\nOr perhaps we might consider classification problems, maybe whether an item is defective or not. In this case we might use the Bernoulli distribution.\nIf we assume some distribution, then we will want to estimate the parameters of that distribution. Chapter 8 is about parameter estimation, in which we have observed data, and try to fit probability laws to this data. We will learn about maximum likelihood estimation, and the method of moments, see which method is preferred and why. We will develop the ideas of Bayesian inference, and define an efficient estimator, and prove the famous Cramér-Rao inequality.\nWe will also derive properties of the distribution of our Maximum Likelihood Estimator \\(\\hat{\\theta}_{\\mathrm{mle}}\\), \\[\n\\hat{\\theta}_{\\mathrm{mle}} = \\operatorname*{arg\\,max}_{\\theta \\in \\Theta} \\hat{L}_n(\\theta;\\mathbf{y})\n\\]\nwhere \\[\n\\sqrt{n}(\\hat{\\theta}_{\\mathrm{mle}}-\\theta_0) \\rightarrow \\mathcal{N}(0, \\mathcal{I}^{-1})\n\\]\n\nand \\(\\mathcal{I}\\) is the Fisher information. All this is in Chapter 8 of our text, which is perhaps the most mathematical of the material we will cover.\n\n\n\nHypothesis Testing\n\nThis is the topic of Chapter 9. Hypothesis tests is a method of statistical inference in which we decide if the observed data supports a particular hypothesis. We will learn about the Neyman-Pearson paradigm. We also look at various tests, including goodness of fit, which we will also look at in Chapter 11. We will define the power of a test, and also look at the duality of hypothesis tests and confidence intervals.\nWe will further develop the ideas of hypothesis testing in Chapter 11, when we look at classical and nonparametric methods for two-sample tests, and in Chapters 12 and 13 we will see how ANOVA is used to compare multiple groups. Chapters 9 and 13 deal with categorical data, so we will look at these together.\nWe will also look at more computationally intensive resampling methods such as permutation tests.\n\n\n\nLinear Models\n\nChapter 14 is about linear least squares. We will go over the simple regression model in some detail, but only briefly cover the more general treatment.\n\n\n\nThe Bayesian Paradigm\n\nMost of the time, we will use a classical, frequentist approach to our analysis, in which parameters are fixed quantities, and probability statements are made only about sampled data and estimates.\nIn Bayesian statistics, the parameters are random, and we assume a distribution that reflects our beliefs about them. Then we update our beliefs given the observed data.\nWe compute posterior distributions (post-data) using Bayes’ Rule.\n\n\n\n\nImage from Nieves “An Actual Introduction to Bayesian Statistics (2021)”, cantorsparadise.com\n\n\n\n(Rice 2006; Wasserman 2004; Pimentel 2024; Blitzstein and Hwang 2019)",
    "crumbs": [
      "Lecture 1: Syllabus & Diagnostic Test"
    ]
  },
  {
    "objectID": "lectures/lecture-1.html#references",
    "href": "lectures/lecture-1.html#references",
    "title": "Syllabus, Course Overview, and Diagnostic Test",
    "section": "References",
    "text": "References\n\n\nBlitzstein, Joseph K., and Jessica Hwang. 2019. Introduction to Probability. CRC Press.\n\n\nPimentel, Sam. 2024. “STAT 135 Lecture Slides.” Lecture slides (shared privately).\n\n\nRice, John A. 2006. Mathematical Statistics and Data Analysis. 3rd ed. Duxbury Press.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. New York: Springer.",
    "crumbs": [
      "Lecture 1: Syllabus & Diagnostic Test"
    ]
  },
  {
    "objectID": "lectures/lecture-2.html",
    "href": "lectures/lecture-2.html",
    "title": "Survey Sampling: An Introduction",
    "section": "",
    "text": "In this chapter, we look at the topic of survey sampling, which involves a particular type of inference, saying something about a population, given an observed subset of the population. By now, we are all very used to sample surveys, such as presidential approval polls, and polls on various issues such as: What percentage of Republicans support vaccine requirements for children to attend public schools. Pew Research investigated this question a couple of years ago, which they attempted to answer by taking a sample of Republican voters, and then drawing a conclusion about the population of Republican voters.\n\n\n\n\n\nNews outlets are constantly publishing polls, which are certainly not all the same quality. The famous FiveThirtyEight site, started by Nate Silver, is defunct now, but it was famous for its pollster ratings. You can read about their methodology and here are their rankings from a couple of years ago.\n\n\n\nFiveThirtyEight pollster ratings from January 2024\n\n\nIn our course, we learn a little bit about survey sampling, and if you like it, you might think about taking Stat 152 the next time it is offered in our department. Chapter 7 in our text discusses the probabilistic sampling techniques, in that each population unit has a specified probability of being included in the sample, which consists of randomly selected units from the population. Note that we make no distributional assumptions in this chapter. We will restrict our study to Simple Random Samples: every population unit has the same probability of being selected, and each particular sample of size \\(n\\) has the same probability. That is, if the size of our population is \\(N\\), then each of the \\(\\displaystyle \\binom{N}{n}\\) possible samples of size \\(n\\) taken without replacement has the same probability.\n\n\nConsider the following problem:\nYou have a box containing 5 cards. Four of the cards are labeled with the number \\(0\\) and one of them is labeled with the number \\(1\\).You pick two cards at random with replacment. Let \\(Y\\) represent the average of the two cards.\n\nWhat is the distribution of the random variable \\(Y\\)? (Hint: Define \\(X\\) to be the sum of the two cards. What is the distribution of \\(X\\)?)\n\n\n\nCheck your answer\n\n\\(X \\sim Bin(2, \\dfrac{1}{5})\\), and \\(Y = X/2\\).\n\\(P(Y = 0) = P(X = 0) = \\dfrac{16}{25}\\)\n\\(P(Y = \\dfrac{1}{2}) = P(X = 1) = \\dfrac{8}{25}\\)\n\\(P(Y = 1) = P(X = 2) = \\dfrac{1}{25}\\)\n\n\nCompute \\(E(Y)\\) and \\(\\mathrm{Var}(Y)\\).\n\n\n\nCheck your answer\n\n\\(E(Y) = \\dfrac{1}{5}\\) and \\(\\mathrm{Var}(Y) = \\dfrac{2}{25}\\).\n\nNow what if I sample without replacement? Let \\(Z\\) be the average of the two tickets in this case. What is the distribution of \\(Z\\)?\n\n\nCheck your answer\n\nNow the sum is Hypergeometric. (What are the parameters of the distribution?)\nYou can work out that \\(P(Z = 0) = \\dfrac{3}{5}, P(Z = \\dfrac{1}{2}) = \\dfrac{2}{5}\\).\nWhy can’t \\(Z\\) be \\(1\\)?",
    "crumbs": [
      "Lecture 2: Survey Sampling, Introduction"
    ]
  },
  {
    "objectID": "lectures/lecture-2.html#introduction",
    "href": "lectures/lecture-2.html#introduction",
    "title": "Survey Sampling: An Introduction",
    "section": "",
    "text": "In this chapter, we look at the topic of survey sampling, which involves a particular type of inference, saying something about a population, given an observed subset of the population. By now, we are all very used to sample surveys, such as presidential approval polls, and polls on various issues such as: What percentage of Republicans support vaccine requirements for children to attend public schools. Pew Research investigated this question a couple of years ago, which they attempted to answer by taking a sample of Republican voters, and then drawing a conclusion about the population of Republican voters.\n\n\n\n\n\nNews outlets are constantly publishing polls, which are certainly not all the same quality. The famous FiveThirtyEight site, started by Nate Silver, is defunct now, but it was famous for its pollster ratings. You can read about their methodology and here are their rankings from a couple of years ago.\n\n\n\nFiveThirtyEight pollster ratings from January 2024\n\n\nIn our course, we learn a little bit about survey sampling, and if you like it, you might think about taking Stat 152 the next time it is offered in our department. Chapter 7 in our text discusses the probabilistic sampling techniques, in that each population unit has a specified probability of being included in the sample, which consists of randomly selected units from the population. Note that we make no distributional assumptions in this chapter. We will restrict our study to Simple Random Samples: every population unit has the same probability of being selected, and each particular sample of size \\(n\\) has the same probability. That is, if the size of our population is \\(N\\), then each of the \\(\\displaystyle \\binom{N}{n}\\) possible samples of size \\(n\\) taken without replacement has the same probability.\n\n\nConsider the following problem:\nYou have a box containing 5 cards. Four of the cards are labeled with the number \\(0\\) and one of them is labeled with the number \\(1\\).You pick two cards at random with replacment. Let \\(Y\\) represent the average of the two cards.\n\nWhat is the distribution of the random variable \\(Y\\)? (Hint: Define \\(X\\) to be the sum of the two cards. What is the distribution of \\(X\\)?)\n\n\n\nCheck your answer\n\n\\(X \\sim Bin(2, \\dfrac{1}{5})\\), and \\(Y = X/2\\).\n\\(P(Y = 0) = P(X = 0) = \\dfrac{16}{25}\\)\n\\(P(Y = \\dfrac{1}{2}) = P(X = 1) = \\dfrac{8}{25}\\)\n\\(P(Y = 1) = P(X = 2) = \\dfrac{1}{25}\\)\n\n\nCompute \\(E(Y)\\) and \\(\\mathrm{Var}(Y)\\).\n\n\n\nCheck your answer\n\n\\(E(Y) = \\dfrac{1}{5}\\) and \\(\\mathrm{Var}(Y) = \\dfrac{2}{25}\\).\n\nNow what if I sample without replacement? Let \\(Z\\) be the average of the two tickets in this case. What is the distribution of \\(Z\\)?\n\n\nCheck your answer\n\nNow the sum is Hypergeometric. (What are the parameters of the distribution?)\nYou can work out that \\(P(Z = 0) = \\dfrac{3}{5}, P(Z = \\dfrac{1}{2}) = \\dfrac{2}{5}\\).\nWhy can’t \\(Z\\) be \\(1\\)?",
    "crumbs": [
      "Lecture 2: Survey Sampling, Introduction"
    ]
  },
  {
    "objectID": "lectures/lecture-2.html#definitions-and-vocabulary",
    "href": "lectures/lecture-2.html#definitions-and-vocabulary",
    "title": "Survey Sampling: An Introduction",
    "section": "Definitions and vocabulary",
    "text": "Definitions and vocabulary\nThe figure below, adapted from Lohr’s book on sampling, shows that we have to be careful regarding the scope of our conclusions. We can only generalize from results from our sample to the sampled population, even if the target population (the population we are interested in) is something different!\n\n\n\n\n\n\nPopulation: the complete set of individuals or entities that we are interested in. We usually only have data on a subset of them (a sample). We will assume that our population is of (finite) size \\(N\\), and that associated with each member or unit of the population is some numerical value. We will denote these numbers by \\(x_1, x_2, \\ldots, x_N\\). If the values of the \\(x_i\\) are \\(0\\) or \\(1\\) then we are usually investigating the presence or absence of some characteristic, such as a particular party affiliation. In this case, our population is dichotomous or binary.\n\n\nParameter: any quantifiable feature of a population. For now, we will assume that the parameter is fixed but unknown.\nFor example: The mean age of all undergraduate students at UC Berkeley.\n\nThe most common population parameters that we are interested in are:\n\nPopulation mean or average: this is denoted by \\(\\mu\\) and defined to be: \\[\n\\mu = \\dfrac{1}{N}\\sum_{i = 1}^N x_i\n\\]\n\n\nPopulation proportion: This is just the population mean in the binary case, and we represent this special mean by \\(p\\) rather than \\(\\mu\\).\n\nOther parameters that we will consider:\n\nPopulation total: this is denoted by \\(\\tau\\) and defined to be: \\[\n\\tau = \\sum_{i = 1}^N x_i = N\\mu\n\\] Note that for a binary population, \\(\\tau\\) represents how many population units possess the characteristic of interest.\n\n\nPopulation variance: this is denoted by \\(\\sigma^2\\) and defined to be: \\[\n\\sigma^2 = \\dfrac{1}{N}\\sum_{i = 1}^N (x_i-\\mu)^2\n\\] The population standard deviation is the square root of the population variance.\n\nExercise: Show that \\(\\sigma^2\\) reduces to \\(\\displaystyle \\dfrac{1}{N}\\sum_{i = 1}^N x_i^2 -\\mu^2\\), and if the \\(x_i\\) are \\(0\\) or \\(1\\) only, then \\(\\sigma^2 = p(1-p)\\).\nExercise Going back to the results of the Pew Research survey shown at the beginning of these notes. What is the population and the parameter of interest?\n\n\nCheck your answer\n\nPopulation: US adults\nParameter: Percentage of US adults that think healthy children should be required to be vaccinated in order to attend public schools.\n\nExercise Consider a population of size 4: \\(\\{x_1, x_2, x_3, x_4\\}\\).\n\nIf we use simple random sampling, how many samples of size 2 will we have? What would be the expected value of the sample mean? Is it equal to the population mean?\nIf, rather than a simple random sample, when all samples of size 2 are equally likely, we use a different probabilistic scheme for getting our samples of size 2: the following four samples are equally likely, and only these samples are possible: \\(\\{x_1, x_2\\}, \\{x_2, x_3\\}, \\{x_3, x_4\\}, \\{x_1, x_4\\}\\). What would be the expected value of the sample mean? Is it equal to the population mean?\n\n\n(Rice 2006; Wasserman 2004; Pimentel 2024; Lohr 2010)",
    "crumbs": [
      "Lecture 2: Survey Sampling, Introduction"
    ]
  },
  {
    "objectID": "lectures/lecture-2.html#references",
    "href": "lectures/lecture-2.html#references",
    "title": "Survey Sampling: An Introduction",
    "section": "References",
    "text": "References\n\n\nLohr, Sharon L. 2010. Sampling: Design and Analysis. 2nd ed. Cengage.\n\n\nPimentel, Sam. 2024. “STAT 135 Lecture Slides.” Lecture slides (shared privately).\n\n\nRice, John A. 2006. Mathematical Statistics and Data Analysis. 3rd ed. Duxbury Press.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. New York: Springer.",
    "crumbs": [
      "Lecture 2: Survey Sampling, Introduction"
    ]
  },
  {
    "objectID": "lectures/lecture-6.html",
    "href": "lectures/lecture-6.html",
    "title": "More about Estimators and Mathematical Digressions",
    "section": "",
    "text": "In this chapter, we discuss what are some desirable properties that an estimator should have. This is just the beginning of the discussion and we will continue it when we study the method of maximum likelihood estimation. So far, we have discussed three criteria of estimators:\n\nUnbiasedness\nLow variance\nLow MSE (Mean Square Error)\n\n\n\nRecall that we call an estimator \\(\\hat{\\theta}\\) unbiased if on average, the estimator is on target. That means that if we are trying to estimate \\(\\theta\\), then \\(E(\\hat{\\theta}) = \\theta\\). For example, since \\(E(\\overline{X}) = \\mu\\), the population mean, the sample mean \\(\\overline{X}\\) is an unbiased estimator of the population mean, and \\(\\hat{p}\\), the sample proportion, is an unbiased estimator of the population proportion.\nExercise Let \\(X_1, \\ldots, X_n\\) be an IID sample from some distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\). Show that \\(S^2\\) is an unbiased estimator of \\(\\sigma^2\\), where \\(\\displaystyle S^2 = \\dfrac{1}{n-1}\\sum_{i=1}^n \\left(X_i - \\overline{X}\\right)^2\\) is the sample variance of \\(X_1, \\ldots, X_n\\).\nExercise Consider an IID random sample \\(X_1, \\ldots, X_n\\) from a \\(Unif(0,b)\\) distribution. Find \\(\\hat{b}\\), the method of moments estimate of \\(b\\)? Is \\(\\hat{b}\\) an unbiased estimator? What about \\(\\hat{b}^2\\)? Is it an unbiased estimator of \\(b^2\\)?\nAs we saw in the previous chapters, if the expectation of the estimator is the true value times multiplied by a constant, then we can just divide the estimator by the constant and this will make the estimator unbiased. That is, if \\(E(\\hat{\\theta}) = c\\theta\\), where \\(c\\) is a constant, then since \\(E(\\dfrac{\\hat{\\theta}}{c}) = \\dfrac{c\\theta}{c} = \\theta\\).\n\n\n\nThis is important since it increases the accuracy of the estimator. The last paragraph shows that we can get rid of a bias, but if an estimator has high variability, there is not much we can do. A low variance implies that the standard error of the estimator is low, which is a desirable property.\n\n\n\nRecall that \\(MSE = \\mathrm{bias}^2 + \\mathrm{Variance}.\\) Since the MSE combines both bias and variance, it is very useful for comparing estimators that may be biased.\nExercise (Chihara and Hesterberg 2018) Let \\(X \\sim Bin(n,p)\\), where \\(n\\) is known and \\(p\\) is unknown. Show that the sample proportion \\(\\hat{p}_1 = X/n\\) is an unbiased estimator of \\(p\\), and that \\(MSE\\left(\\hat{p}_1\\right) = \\dfrac{p(1-p)}{n}\\).\nSuppose we define an alternative estimator of \\(p\\), denoted by \\(\\hat{p}_2\\), where \\(\\hat{p}_2 = \\dfrac{X+1}{n+2}\\), that is, we add one artificial success and one artifical failure to the data. What is \\(E(\\hat{p}_2)\\)? Is \\(\\hat{p}_2\\) unbiased? Compute \\(\\mathrm{Bias}(\\hat{p}_2) = E(\\hat{p}_2) -p\\), the variance of \\(\\hat{p}_2\\), and the MSE of \\(\\hat{p}_2\\). Which estimator would you use, \\(\\hat{p}_1\\) or \\(\\hat{p}_2\\)?\n\n\n\nAll these criteria are well and fine, but one thing we would definitely like is that as our sample size gets larger and larger (we get more data), our estimator should become more accurate. In fact, as \\(n \\rightarrow \\infty\\), we would like \\(\\hat{\\theta} \\equiv \\hat{\\theta}_n\\) to converge to \\(\\theta\\) (the \\(n\\) denotes the size of the sample that we are using), whatever “converge” might mean here. In fact, the convergence here is what we call convergence in probability, which basically means that in the long run, the probability of \\(\\hat{\\theta}_n\\) being very close to \\(\\theta\\) goes to 1.\n\nConsistent: Let \\(\\hat{\\theta}_n\\) be an estimator of a parameter \\(\\theta\\), based on a sample of size \\(n\\). We say that \\(\\hat{\\theta}_n\\) is consistent in probability if \\(\\hat{\\theta}_n\\) converges in probability to \\(\\theta\\) as \\(n \\rightarrow \\infty\\); that is, for any \\(\\varepsilon &gt; 0\\), we have that \\(\\displaystyle \\lim_{n \\rightarrow \\infty} P\\left(\\lvert \\hat{\\theta}_n -\\theta \\rvert &gt; \\varepsilon \\right)=0\\). We write this as \\(\\hat{\\theta}_n \\overset{P}{\\rightarrow} \\theta\\).\n\nThis is saying that for any acceptable amount of error epsilon, the probability of an actual error that is greater than epsilon goes to 0. This means that the error might be large on events of very low probability, and these probabilities get lower as \\(n\\) gets larger. If the sample is large enough, therefore, the estimator is very likely to be close to its target.",
    "crumbs": [
      "Lecture 6: MoM & Mathematical Digressions"
    ]
  },
  {
    "objectID": "lectures/lecture-6.html#properties-of-estimators",
    "href": "lectures/lecture-6.html#properties-of-estimators",
    "title": "More about Estimators and Mathematical Digressions",
    "section": "",
    "text": "In this chapter, we discuss what are some desirable properties that an estimator should have. This is just the beginning of the discussion and we will continue it when we study the method of maximum likelihood estimation. So far, we have discussed three criteria of estimators:\n\nUnbiasedness\nLow variance\nLow MSE (Mean Square Error)\n\n\n\nRecall that we call an estimator \\(\\hat{\\theta}\\) unbiased if on average, the estimator is on target. That means that if we are trying to estimate \\(\\theta\\), then \\(E(\\hat{\\theta}) = \\theta\\). For example, since \\(E(\\overline{X}) = \\mu\\), the population mean, the sample mean \\(\\overline{X}\\) is an unbiased estimator of the population mean, and \\(\\hat{p}\\), the sample proportion, is an unbiased estimator of the population proportion.\nExercise Let \\(X_1, \\ldots, X_n\\) be an IID sample from some distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\). Show that \\(S^2\\) is an unbiased estimator of \\(\\sigma^2\\), where \\(\\displaystyle S^2 = \\dfrac{1}{n-1}\\sum_{i=1}^n \\left(X_i - \\overline{X}\\right)^2\\) is the sample variance of \\(X_1, \\ldots, X_n\\).\nExercise Consider an IID random sample \\(X_1, \\ldots, X_n\\) from a \\(Unif(0,b)\\) distribution. Find \\(\\hat{b}\\), the method of moments estimate of \\(b\\)? Is \\(\\hat{b}\\) an unbiased estimator? What about \\(\\hat{b}^2\\)? Is it an unbiased estimator of \\(b^2\\)?\nAs we saw in the previous chapters, if the expectation of the estimator is the true value times multiplied by a constant, then we can just divide the estimator by the constant and this will make the estimator unbiased. That is, if \\(E(\\hat{\\theta}) = c\\theta\\), where \\(c\\) is a constant, then since \\(E(\\dfrac{\\hat{\\theta}}{c}) = \\dfrac{c\\theta}{c} = \\theta\\).\n\n\n\nThis is important since it increases the accuracy of the estimator. The last paragraph shows that we can get rid of a bias, but if an estimator has high variability, there is not much we can do. A low variance implies that the standard error of the estimator is low, which is a desirable property.\n\n\n\nRecall that \\(MSE = \\mathrm{bias}^2 + \\mathrm{Variance}.\\) Since the MSE combines both bias and variance, it is very useful for comparing estimators that may be biased.\nExercise (Chihara and Hesterberg 2018) Let \\(X \\sim Bin(n,p)\\), where \\(n\\) is known and \\(p\\) is unknown. Show that the sample proportion \\(\\hat{p}_1 = X/n\\) is an unbiased estimator of \\(p\\), and that \\(MSE\\left(\\hat{p}_1\\right) = \\dfrac{p(1-p)}{n}\\).\nSuppose we define an alternative estimator of \\(p\\), denoted by \\(\\hat{p}_2\\), where \\(\\hat{p}_2 = \\dfrac{X+1}{n+2}\\), that is, we add one artificial success and one artifical failure to the data. What is \\(E(\\hat{p}_2)\\)? Is \\(\\hat{p}_2\\) unbiased? Compute \\(\\mathrm{Bias}(\\hat{p}_2) = E(\\hat{p}_2) -p\\), the variance of \\(\\hat{p}_2\\), and the MSE of \\(\\hat{p}_2\\). Which estimator would you use, \\(\\hat{p}_1\\) or \\(\\hat{p}_2\\)?\n\n\n\nAll these criteria are well and fine, but one thing we would definitely like is that as our sample size gets larger and larger (we get more data), our estimator should become more accurate. In fact, as \\(n \\rightarrow \\infty\\), we would like \\(\\hat{\\theta} \\equiv \\hat{\\theta}_n\\) to converge to \\(\\theta\\) (the \\(n\\) denotes the size of the sample that we are using), whatever “converge” might mean here. In fact, the convergence here is what we call convergence in probability, which basically means that in the long run, the probability of \\(\\hat{\\theta}_n\\) being very close to \\(\\theta\\) goes to 1.\n\nConsistent: Let \\(\\hat{\\theta}_n\\) be an estimator of a parameter \\(\\theta\\), based on a sample of size \\(n\\). We say that \\(\\hat{\\theta}_n\\) is consistent in probability if \\(\\hat{\\theta}_n\\) converges in probability to \\(\\theta\\) as \\(n \\rightarrow \\infty\\); that is, for any \\(\\varepsilon &gt; 0\\), we have that \\(\\displaystyle \\lim_{n \\rightarrow \\infty} P\\left(\\lvert \\hat{\\theta}_n -\\theta \\rvert &gt; \\varepsilon \\right)=0\\). We write this as \\(\\hat{\\theta}_n \\overset{P}{\\rightarrow} \\theta\\).\n\nThis is saying that for any acceptable amount of error epsilon, the probability of an actual error that is greater than epsilon goes to 0. This means that the error might be large on events of very low probability, and these probabilities get lower as \\(n\\) gets larger. If the sample is large enough, therefore, the estimator is very likely to be close to its target.",
    "crumbs": [
      "Lecture 6: MoM & Mathematical Digressions"
    ]
  },
  {
    "objectID": "lectures/lecture-6.html#types-of-convergence",
    "href": "lectures/lecture-6.html#types-of-convergence",
    "title": "More about Estimators and Mathematical Digressions",
    "section": "Types of Convergence",
    "text": "Types of Convergence\nBefore we go any further, let’s briefly talk about the three different kinds of ways of interpreting the statement \\(\\hat{\\theta}_n \\rightarrow \\theta\\) that you might encounter while studying probability - well, you will mostly encounter the first two, but you might have seen the third in a course on real analysis or measure theory.\nLet \\(X_1, X_2, \\ldots\\) be a sequence of random variables, such that \\(X_n\\) has cdf \\(F_n\\), and let \\(X\\) be another random variable with CDF \\(F\\).\n\n\\(X_n\\) converges in distribution to \\(X\\), written as \\(X_n \\overset{D}{\\rightarrow} X\\), if \\(P(X_n \\le x) \\rightarrow P(X \\le x)\\) as \\(n \\rightarrow \\infty\\) at all points \\(x\\) at which the function \\(F(x) = P(X \\le x)\\) is continuous. This means that the CDFs of the \\(X_n\\) converge to the CDF of \\(X\\) (\\(F_n \\rightarrow F\\) as \\(n\\rightarrow \\infty\\)).\n\\(X_n\\) converges in probability to \\(X\\), written as \\(X_n \\overset{P}{\\rightarrow} X\\), if, for all \\(\\varepsilon &gt; 0\\), we have that \\(P(\\lvert X_n - X \\rvert &gt; \\varepsilon) \\rightarrow 0\\) as \\(n \\rightarrow \\infty\\). This isn’t saying that we guarantee that \\(X_n\\) will get very close to \\(X\\) for large \\(n\\). We are saying that it is very likely.\n\\(X_n\\) converges almost surely, written as \\(X_n \\overset{a.s.}{\\rightarrow} X\\), if \\(\\displaystyle P\\left(\\lim_{n\\rightarrow \\infty} X_n = X\\right) =1\\). That is, the event \\(\\{\\omega \\in \\Omega: \\displaystyle \\lim_{n\\rightarrow \\infty} X_n(\\omega) = X(\\omega)\\}\\) has probability 1. This convergence guarantees that \\(X_n\\) will converge to \\(X\\) except on a set of measure 0 (for example, on finitely many points in a continuous interval).\n\nYou can see that the first type is the weakest, and the last is the strongest. \\[\n\\left(X_n \\overset{a.s.}{\\rightarrow} X\\right) \\Rightarrow \\left(X_n \\overset{P}{\\rightarrow} X\\right) \\Rightarrow \\left(X_n \\overset{D}{\\rightarrow} X\\right)\n\\]\nThat is, if we have that \\(X_1, \\ldots\\) converge to \\(X\\) a.s., then the other forms of convergence will also be true.\nHere is an example (Grimmett and Stirzaker 2001): Suppose \\(X\\sim Bernoulli(1/2)\\), and \\(X_1, \\ldots\\) are identical random variables, with \\(X_n = X\\) for all \\(n\\). Now the \\(X_n\\) are not independent, but \\(X_n \\overset{D}{\\rightarrow}X\\). If \\(Y = 1-X\\), then \\(X\\) and \\(Y\\) have the same distribution, which means that \\(X_n \\overset{D}{\\rightarrow} Y\\). But \\(X_n\\) cannot converge to \\(Y\\) in any other sense because \\(\\lvert X_n - Y\\rvert = 1\\) always.\nWe will revisit two famous limit theorems now, that use different kinds of convergence.\n\nThe Central Limit Theorem\nThe CLT states that for large \\(n\\), the sample mean, suitably standardized, will have a CDF that approaches the CDF of the standard Normal. That is, the standardized sample mean converges in distribution to the standard Normal.\nIf \\(X_1, X_2, \\ldots, X_n\\) is an independent and identically distributed sample from a population with mean \\(\\mu\\) and variance \\(\\sigma^2\\), then:\n\\[\n\\left(\\frac{\\overline{X}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\right) = \\sqrt{n}\\left(\\frac{\\overline{X}-\\mu}{\\sigma}\\right) \\overset{D}{\\longrightarrow}\\mathcal{N}(0,1)  \\text{ as } n\\longrightarrow \\infty\n\\]\n\n\nThe Weak Law of Large Numbers\nLet \\(X_1, X_2, \\ldots, X_n\\) be a sequence of iid random variables with mean \\(\\mu\\) and variance \\(\\sigma^2\\), then if \\(\\overline{X}_n = \\left(= \\dfrac{1}{n} \\sum_{i=1}^{n}X_i \\right)\\) is the sample mean,then for every \\(\\varepsilon &gt; 0\\), we have that \\(\\lim_{n \\rightarrow \\infty} P(\\lvert \\overline{X}_n - \\mu \\rvert &gt; \\varepsilon )=0\\).\nThat is, the sample mean converges in probability to the true mean.",
    "crumbs": [
      "Lecture 6: MoM & Mathematical Digressions"
    ]
  },
  {
    "objectID": "lectures/lecture-6.html#tail-inequalities",
    "href": "lectures/lecture-6.html#tail-inequalities",
    "title": "More about Estimators and Mathematical Digressions",
    "section": "Tail Inequalities",
    "text": "Tail Inequalities\nIn order to prove the WLLN, we need Chebyshev’s inequality. In order to prove Chebyshev’s inequality, we need Markov’s inequality. These are both called tail inequalities because they bound the tail of the distribution. That is, they put bounds on the probability that the random variable takes very large values.\n\nMarkov’s inequality\nIf \\(X\\) is a nonnegative random variable (\\(P(X\\ge 0 ) = 1\\)) such that \\(E(X) &lt; \\infty\\) (that is, the expectation exists), then for any \\(c&gt; 0\\), \\[\nP(X \\ge c) \\le \\dfrac{E(X)}{c}.\n\\]\nNotice that this is a very simple inequality, and requires nothing but that the random variable be nonnegative. The proof is very simple - we just have to write the expected value as a sum over the region where \\(X &lt; c\\) and where \\(X \\ge c\\). Try it.\n\n\nChebyshev’s inequality\nIf \\(X\\) is a random variable wtih mean \\(\\mu\\) and variance \\(\\sigma^2\\), then we have that for any \\(c&gt;0\\),\n\\[\nP(\\lvert X-\\mu\\rvert&gt; c)\\le \\dfrac{\\sigma^2}{c^2}.\n\\]\nExercise Apply Markov’s inequality to \\(\\lvert X - \\mu\\rvert^2\\) to prove Chebyshev’s inequality.\n\n\nConsequences of the WLLN\nPlease work through the following consequences of the WLLN:\n\nIf \\(X_n \\xrightarrow{P} X\\) and \\(Y_n \\xrightarrow{P} Y\\), then\n\\[\nX_n + Y_n \\xrightarrow{P} X + Y.\n\\]\nIf \\(X_n \\xrightarrow{P} X\\) and \\(c\\) is a constant, then\n\\[\nc X_n \\xrightarrow{P} c X.\n\\]\nIf \\(X_n \\xrightarrow{P} a\\) and the real-valued function \\(g\\) is continuous at \\(a\\), then\n\\[\ng(X_n) \\xrightarrow{P} g(a).\n\\]\nIf \\(X_n \\xrightarrow{P} X\\) and \\(Y_n \\xrightarrow{P} Y\\), then\n\\[\nX_n Y_n \\xrightarrow{P} X Y.\n\\]\n\n\n\nSample moments converge to the true moments of the distribution\nThis is another important consequence of the WLLN. That is,The sample moments (\\(\\hat{\\mu}_k\\)) converge to the population moments (\\(\\mu_k = E(X^k)\\)). If the functions relating the estimator \\(\\hat{\\theta}\\) to the sample moments are continuous, then the estimator will converge to the parameter as the sample moments converge to the population moments.\nTherefore, the WLLN implies that the sample mean (\\(\\overline{X}_n\\)) is a consistent estimator of \\(\\mu\\).\nRecall the sample variance \\(\\displaystyle S^2  = \\dfrac{1}{n-1}\\sum_{i=1}^n \\left(X_i - \\overline{X}_n\\right)^2\\). Is \\(S^2\\) a consistent estimator of \\(\\sigma^2\\)?\nWhat about \\(\\hat{\\sigma}^2 = \\dfrac{n-1}{n}S^2\\)?\n\n[Rice (2006); Wasserman (2004); Pimentel (2024); Chihara and Hesterberg (2018); Grimmett and Stirzaker (2001);]",
    "crumbs": [
      "Lecture 6: MoM & Mathematical Digressions"
    ]
  },
  {
    "objectID": "lectures/lecture-6.html#references",
    "href": "lectures/lecture-6.html#references",
    "title": "More about Estimators and Mathematical Digressions",
    "section": "References",
    "text": "References\n\n\nChihara, Laura M., and Tim C. Hesterberg. 2018. Mathematical Statistics with Resampling and r. John Wiley & Sons, Hoboken, NJ.\n\n\nGrimmett, Geoffrey R., and David R. Stirzaker. 2001. Probability and Random Processes. 3rd ed. Oxford: Oxford University Press.\n\n\nPimentel, Sam. 2024. “STAT 135 Lecture Slides.” Lecture slides (shared privately).\n\n\nRice, John A. 2006. Mathematical Statistics and Data Analysis. 3rd ed. Duxbury Press.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. New York: Springer.",
    "crumbs": [
      "Lecture 6: MoM & Mathematical Digressions"
    ]
  },
  {
    "objectID": "lectures/macros.html",
    "href": "lectures/macros.html",
    "title": "",
    "section": "",
    "text": "\\[\n\\newcommand{\\trans}{^\\mathsf{T}}\n\\newcommand{\\eps}{\\epsilon}\n\\]"
  },
  {
    "objectID": "lectures/lecture-7.html",
    "href": "lectures/lecture-7.html",
    "title": "Computing Standard Errors",
    "section": "",
    "text": "We have used the method of moments to obtain an estimator \\(\\hat{\\theta}_n\\) for the parameter of interest \\(\\theta\\), based on an IID random sample \\(X_1, \\ldots, X_n\\) from the distribution. Once we have an estimator, we would like to know how stable or reliable it is, that is, if we draw another sample, how much would the value of the estimator change? To understand this, we usually need to derive the sampling distribution of the estimator (not easy, unless we are dealing with the sample mean), or approximate its sampling distribution. The standard deviation of the sampling distribution is called the standard error of the estimator, and we need to derive or approximate this standard error.\nIt might be that the sampling distribution is explicitly of a functional form depending on the parameter values. We can just use our estimates and get an estimate for the standard error. If this functional form is too complicated to write down explicitly, we could simulate it, that is, use the bootstrap method to approximate the sampling distribution of the estimator.\nNote that the WLLN implies that the sample moments converge in probability to the true (population) moments. This means that if the functions relating the estimator \\(\\hat{\\theta}\\) to the sample moments is continuous, the estimator will converge to the parameter as the sample moments converge to the population moments.",
    "crumbs": [
      "Lecture 7: Standard Errors of MoM Estimators"
    ]
  },
  {
    "objectID": "lectures/lecture-7.html#the-standard-error-of-the-method-of-moments-estimator",
    "href": "lectures/lecture-7.html#the-standard-error-of-the-method-of-moments-estimator",
    "title": "Computing Standard Errors",
    "section": "",
    "text": "We have used the method of moments to obtain an estimator \\(\\hat{\\theta}_n\\) for the parameter of interest \\(\\theta\\), based on an IID random sample \\(X_1, \\ldots, X_n\\) from the distribution. Once we have an estimator, we would like to know how stable or reliable it is, that is, if we draw another sample, how much would the value of the estimator change? To understand this, we usually need to derive the sampling distribution of the estimator (not easy, unless we are dealing with the sample mean), or approximate its sampling distribution. The standard deviation of the sampling distribution is called the standard error of the estimator, and we need to derive or approximate this standard error.\nIt might be that the sampling distribution is explicitly of a functional form depending on the parameter values. We can just use our estimates and get an estimate for the standard error. If this functional form is too complicated to write down explicitly, we could simulate it, that is, use the bootstrap method to approximate the sampling distribution of the estimator.\nNote that the WLLN implies that the sample moments converge in probability to the true (population) moments. This means that if the functions relating the estimator \\(\\hat{\\theta}\\) to the sample moments is continuous, the estimator will converge to the parameter as the sample moments converge to the population moments.",
    "crumbs": [
      "Lecture 7: Standard Errors of MoM Estimators"
    ]
  },
  {
    "objectID": "lectures/lecture-7.html#computing-the-standard-error-of-hattheta",
    "href": "lectures/lecture-7.html#computing-the-standard-error-of-hattheta",
    "title": "Computing Standard Errors",
    "section": "Computing the Standard Error of \\(\\hat{\\theta}\\)",
    "text": "Computing the Standard Error of \\(\\hat{\\theta}\\)\nWe have three possible cases when we want to compute \\(SE(\\hat{\\theta})\\):\n\n\\(\\hat{\\theta}\\) is a linear function of the first sample moment \\(\\hat{\\mu}_1\\), in which case we can compute it directly.\n\\(\\hat{\\theta}\\) is a nonlinear function of \\(\\hat{\\mu}_1\\). In this case we will use the univariate delta method, that we will describe shortly.\n\\(\\hat{\\theta}\\) is more complex, perhaps uses more moments, and in this case we could use the bootstrap.\n\n\nCase 1: \\(\\hat{\\theta}\\) is a linear function of \\(\\hat{\\mu}_1\\)\nWe will do this with an example. Consider an IID random sample from the Poisson distribution, whose rate \\(\\lambda\\) is unknown: \\[\nX_1, \\ldots, X_n \\overset{IID}{\\sim} Poisson(\\lambda) \\Rightarrow  E(X) = Var(X) =\\lambda\n\\] The method of moments estimator of \\(\\lambda\\) is therefore just \\(\\hat{\\lambda}_n = \\hat{\\mu}_1 = \\overline{X}_n\\).\nThis implies that we can use the Central Limit Theorem to approximate the distribution of \\(\\hat{\\lambda}_n\\).\nNote that \\(SE(\\hat{\\lambda}_n) = SE( \\overline{X}_n) = \\dfrac{\\sigma}{\\sqrt{n}} = \\sqrt{\\dfrac{\\lambda}{n}}.\\)\nThis tells us that the sampling distribution of \\(\\hat{\\lambda}_n\\) becomes more concentrated about the true value \\(\\lambda\\) as \\(n\\) gets large. In order to get an idea of the standard error, we can just substitute \\(\\hat{\\lambda}_n\\) for \\(\\lambda\\), and therefore, our estimated standard error of \\(\\hat{\\lambda}_n\\) is given by \\[\ns_{\\hat{\\lambda}_n} = \\sqrt{\\dfrac{\\hat{\\lambda}_n}{n}}.\n\\]\nNote that actually what is true is that \\[\n\\sigma_{\\hat{\\lambda}_n} = \\sqrt{\\dfrac{\\lambda}{n}}.\n\\]\nBut because our estimator is consistent, we know that \\(\\hat{\\mu}_1 \\rightarrow \\mu = \\lambda\\). Since \\(\\sqrt{\\dfrac{\\hat{\\lambda}_n}{n}}\\) is a continuous function of \\(\\hat{\\lambda}_n\\), we will have\n\\[\n\\sqrt{\\dfrac{\\hat{\\lambda}_n}{n}} \\rightarrow \\sqrt{\\dfrac{\\lambda}{n}}.\n\\]\n\n\nCase 2: \\(\\hat{\\theta}\\) is a nonlinear function of \\(\\hat{\\mu}_1\\)\nFor example, consider the following situation: \\(\\displaystyle X_1, \\ldots, X_n \\overset{i.i.d.}\\sim Exp(\\lambda) \\Rightarrow  E(X) = \\frac{1}{\\lambda} \\Rightarrow \\hat\\lambda = \\frac{1}{\\overline{X}_n},\\) using the method of moments.\nThis type of situation is common in statistics. We have a random variable \\(X\\) that we know the mean and variance of, or in the case above, we could use the CLT on \\(\\overline{X}_n\\). But we are actually interested in different random variable, \\(Y = g(X)\\), and we want the mean and variance of \\(Y\\). Above, the function \\(g\\) is the reciprocal of the sample mean.\nThe problem is that \\(g\\) is not a linear function, so \\(E\\left(g(X)\\right) \\ne g\\left(E(X)\\right)\\).\nWe could use the bootstrap, but we are going to discuss a different method called the delta method or the propagation of error formula.1 We use a Taylor series expansion of \\(g\\) about \\(\\mu_X\\) and linearize \\(Y = g(X)\\), and similarly we can use a linear function of \\(\\overline{X}_n\\) that will be close for large \\(n\\).\n\n[Rice (2006); Wasserman (2004); Pimentel (2024); Chihara and Hesterberg (2018);]",
    "crumbs": [
      "Lecture 7: Standard Errors of MoM Estimators"
    ]
  },
  {
    "objectID": "lectures/lecture-7.html#references",
    "href": "lectures/lecture-7.html#references",
    "title": "Computing Standard Errors",
    "section": "References",
    "text": "References\n\n\nChihara, Laura M., and Tim C. Hesterberg. 2018. Mathematical Statistics with Resampling and r. John Wiley & Sons, Hoboken, NJ.\n\n\nPimentel, Sam. 2024. “STAT 135 Lecture Slides.” Lecture slides (shared privately).\n\n\nRice, John A. 2006. Mathematical Statistics and Data Analysis. 3rd ed. Duxbury Press.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. New York: Springer.",
    "crumbs": [
      "Lecture 7: Standard Errors of MoM Estimators"
    ]
  },
  {
    "objectID": "lectures/lecture-7.html#footnotes",
    "href": "lectures/lecture-7.html#footnotes",
    "title": "Computing Standard Errors",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is discussed in the textbook (Rice 2006) on page 162, in chapter 4.↩︎",
    "crumbs": [
      "Lecture 7: Standard Errors of MoM Estimators"
    ]
  },
  {
    "objectID": "lectures/lecture-5.html",
    "href": "lectures/lecture-5.html",
    "title": "Parameter Estimation: Method of Moments",
    "section": "",
    "text": "So far, we have estimated population parameters, mostly the mean and variance, but our analysis has been distribution-free. We haven’t made any assumptions other than our population being finite, and our sample being a simple random sample.\nNow, we are going to think about parametric models, that is we are going to assume that our populations are infinite, with parametric probability distributions, but unknown parameters.\nWe would use these when we have some reason to believe that our data is being generated with some particular distribution, and we try to figure out the parameters of the distribution, given a sample from this parametric distribution.\nFor instance, counts of goals scored in the soccer world cup, or counts of traffic accidents - or counts of cavalry officers in the Prussian army being kicked to death by their horses - these have been shown to follow a Poisson distribution. Later in the course, we will discuss nonparametric models as well, but it is useful to understand parametric models first, as these are widely used.\nWhen we talk about a family of probability distributions we refer to a class of probability distributions indexed by its parameter values. The shape of the distributions can vary (a lot!) depending on the values of the parameters, but the form of the distribution (given by the pdf or cdf) is determined by the class or the family. Many families of probability distributions, such as Poisson, or Gamma, or Gaussian, are determined by some small number of parameters. For the Poisson, you need the parameter \\(\\lambda\\), which would be the average count, for the Gamma distribution you need two parameters, \\(\\alpha\\), called the shape parameter, and \\(\\lambda\\), called the rate parameter. (Some texts will use \\(\\beta = 1/\\lambda\\) and call it the scale parameter.) The Gaussian family of distributions depends on two parameters, \\(\\mu\\) and \\(\\sigma\\). This means that when we are estimating the parameters of a probability distribution, given sample data, we might need to estimate a single parameter, or we might need to estimate a vector consisting of two or more parameters.\nFor example, here is a figure from Wikipedia’s page on the Normal distribution showing the probability density functions for various values of the parameters \\(\\mu\\) and \\(\\sigma\\).\n\n\n\nNormal family\n\n\nThe pdf has the same form for all of the density curves:\n\\[\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}\n\\]\nEven when we are interested in only one parameter - the parameter of interest - we may need to estimate the remaining parameters in the model in order to estimate it. In some cases, the parameter of interest itself is a complicated function of the underlying model parameters, as in the following example from (Wasserman 2004):\nExample Let \\(X_1, X_2, \\ldots, X_n \\sim \\mathcal{N}(\\mu, \\sigma^2).\\) The parameter is a vector \\(\\mathbf{\\theta} = (\\mu, \\sigma)\\) where \\(\\sigma &gt; 0\\). Suppose that \\(X_i\\) is ther outcome of a blood test and we are interested in \\(\\tau\\), the fraction of the population whose test score is greater than 1. If \\(Z \\sim \\mathcal{N}(0,1)\\), then \\[\n\\begin{align*}\n\\tau &= P(X &gt; 1)\\\\\n&= 1-P(X&lt;1)\\\\\n&= 1 - P\\left(\\frac{X-\\mu}{\\sigma} &gt; \\frac{1-\\mu}{\\sigma}\\right)\\\\\n&= 1 - \\Phi\\left(\\frac{1-\\mu}{\\sigma}\\right)\\\\\n\\end{align*}\n\\] Therefore, the parameter of interest is \\(\\tau = T(\\mu, \\sigma) = \\displaystyle 1 - \\Phi\\left(\\frac{1-\\mu}{\\sigma}\\right)\\), where \\(T\\) denotes that \\(\\tau\\) is a function of \\(\\mu\\) and \\(\\sigma\\).\n\n\n\n\n\nAmericium 241 emitting alpha particles\n\n\n“Records of emissions of alpha particles from radioactive sources show that the number of emissions per unit time is not constant but fluctuates in a seemingly random fashion”.\nThis is an example of what we will do in this chapter. We will assume some distribution, get a data sample, and then use the data sample to estimate the parameter of the distribution we assumed. Since the underlying rate of emission was assumed to be constant, it was assumed that the emissions followed a Poisson distribution. In fact, for this very reason - that the number of emissions per unit time fluctuate randomly, but there is an underlying constant rate - the Poisson distribution is often used to model radioactive decay. Recall the conditions for using the Poisson distribution to model the number of events in time (or space) are that:\n\nThe underlying rate of events is constant in time (or space),\nThe number of events that occur in disjoint intervals are independent, and\nThere cannot be multiple events at the same instant.\n\nResearchers observed the radioactive decay of Americium 241 and the consequent emission of alpha particles, recording the time between successive emissions. They recorded 1,207 intervals of 10 seconds each, and counted the number of emissions in each of these intervals.\nThe table below, reproduced from (Rice 2006) shows emission counts \\(n\\) in the first column. In the second column is the number of intervals the researchers observed that had \\(n\\) emissions, for each \\(n\\) listed. For example, there were 28 10-second intervals observed that had 3 emissions each, 56 intervals that had 4 emissions each, etc. To compute the expected count, we need a value for the Poisson rate \\(\\lambda\\). The observed mean emission rate which was the total number of emissions divided by the total amount of time was recorded to be 0.8392 seconds. We use this observed mean emission rate to compute an estimate for \\(\\lambda\\) in the probability mass function of the Poisson distribution. Now, the 1,207 counts are the 1,207 realizations of a Poisson random variable with rate \\(\\lambda\\), where \\(\\lambda\\) is the expected number of emissions in 10 seconds,making our estimate, \\(\\hat{\\lambda} = 0.8392 \\times 10 = 8.392\\).\nFor example, how many intervals do we expect with exactly 3 emissions? Each interval has 4 emissions or not 4 emissions. So the number of intervals out of 1,207 total intervals with exactly 4 emissions is a Binomial random variable, with parameters \\(n = 1207\\), and \\(p = P(\\) exactly 4 emissions\\()\\) = \\(\\displaystyle \\dfrac{\\lambda^k e^{-\\lambda}}{k!} \\approx \\dfrac{\\hat{\\lambda}^k  e^{-\\hat{\\lambda}}}{k!}\\). If we plug in \\(k=4\\) and \\(\\hat{\\lambda} = 8.392\\), we get that \\(p \\approx 0.0468\\). Therefore, the expected number of intervals with exactly 4 emissions in \\(np = 1207\\times 0.0468 = 56.4876\\approx 56.5\\).\nFor the first row, since we are combining intervals with exactly 0 or 1 or 2 counts, the Binomial parameter \\(p\\) is given by \\(P(\\) exactly 0 OR exactly 1 OR exactly 2 emissions \\()\\), so we have to add the probabilities of each of these to get \\(p\\). We can see that the expected counts are not too far off from the observed counts. In chapter 9 we will discuss how to quantify the notion of “not too far off”.\n\nObserved and Expected Interval Counts for \\(n\\) Alpha Particle Emissions\n\n\n\\(n\\)\nObserved Number of Intervals\nExpected Number of Intervals\n\n\n\n\n0-2\n18\n12.2\n\n\n3\n28\n27.0\n\n\n4\n56\n56.5\n\n\n5\n105\n94.9\n\n\n6\n126\n132.7\n\n\n7\n146\n159.1\n\n\n8\n164\n166.9\n\n\n9\n161\n155.6\n\n\n10\n123\n130.6\n\n\n11\n101\n99.7\n\n\n12\n74\n69.7\n\n\n13\n53\n45.0\n\n\n14\n23\n27.0\n\n\n15\n15\n15.1\n\n\n16\n9\n7.9\n\n\n17+\n5\n7.1",
    "crumbs": [
      "Lecture 5: Method of Moments"
    ]
  },
  {
    "objectID": "lectures/lecture-5.html#introduction",
    "href": "lectures/lecture-5.html#introduction",
    "title": "Parameter Estimation: Method of Moments",
    "section": "",
    "text": "So far, we have estimated population parameters, mostly the mean and variance, but our analysis has been distribution-free. We haven’t made any assumptions other than our population being finite, and our sample being a simple random sample.\nNow, we are going to think about parametric models, that is we are going to assume that our populations are infinite, with parametric probability distributions, but unknown parameters.\nWe would use these when we have some reason to believe that our data is being generated with some particular distribution, and we try to figure out the parameters of the distribution, given a sample from this parametric distribution.\nFor instance, counts of goals scored in the soccer world cup, or counts of traffic accidents - or counts of cavalry officers in the Prussian army being kicked to death by their horses - these have been shown to follow a Poisson distribution. Later in the course, we will discuss nonparametric models as well, but it is useful to understand parametric models first, as these are widely used.\nWhen we talk about a family of probability distributions we refer to a class of probability distributions indexed by its parameter values. The shape of the distributions can vary (a lot!) depending on the values of the parameters, but the form of the distribution (given by the pdf or cdf) is determined by the class or the family. Many families of probability distributions, such as Poisson, or Gamma, or Gaussian, are determined by some small number of parameters. For the Poisson, you need the parameter \\(\\lambda\\), which would be the average count, for the Gamma distribution you need two parameters, \\(\\alpha\\), called the shape parameter, and \\(\\lambda\\), called the rate parameter. (Some texts will use \\(\\beta = 1/\\lambda\\) and call it the scale parameter.) The Gaussian family of distributions depends on two parameters, \\(\\mu\\) and \\(\\sigma\\). This means that when we are estimating the parameters of a probability distribution, given sample data, we might need to estimate a single parameter, or we might need to estimate a vector consisting of two or more parameters.\nFor example, here is a figure from Wikipedia’s page on the Normal distribution showing the probability density functions for various values of the parameters \\(\\mu\\) and \\(\\sigma\\).\n\n\n\nNormal family\n\n\nThe pdf has the same form for all of the density curves:\n\\[\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}\n\\]\nEven when we are interested in only one parameter - the parameter of interest - we may need to estimate the remaining parameters in the model in order to estimate it. In some cases, the parameter of interest itself is a complicated function of the underlying model parameters, as in the following example from (Wasserman 2004):\nExample Let \\(X_1, X_2, \\ldots, X_n \\sim \\mathcal{N}(\\mu, \\sigma^2).\\) The parameter is a vector \\(\\mathbf{\\theta} = (\\mu, \\sigma)\\) where \\(\\sigma &gt; 0\\). Suppose that \\(X_i\\) is ther outcome of a blood test and we are interested in \\(\\tau\\), the fraction of the population whose test score is greater than 1. If \\(Z \\sim \\mathcal{N}(0,1)\\), then \\[\n\\begin{align*}\n\\tau &= P(X &gt; 1)\\\\\n&= 1-P(X&lt;1)\\\\\n&= 1 - P\\left(\\frac{X-\\mu}{\\sigma} &gt; \\frac{1-\\mu}{\\sigma}\\right)\\\\\n&= 1 - \\Phi\\left(\\frac{1-\\mu}{\\sigma}\\right)\\\\\n\\end{align*}\n\\] Therefore, the parameter of interest is \\(\\tau = T(\\mu, \\sigma) = \\displaystyle 1 - \\Phi\\left(\\frac{1-\\mu}{\\sigma}\\right)\\), where \\(T\\) denotes that \\(\\tau\\) is a function of \\(\\mu\\) and \\(\\sigma\\).\n\n\n\n\n\nAmericium 241 emitting alpha particles\n\n\n“Records of emissions of alpha particles from radioactive sources show that the number of emissions per unit time is not constant but fluctuates in a seemingly random fashion”.\nThis is an example of what we will do in this chapter. We will assume some distribution, get a data sample, and then use the data sample to estimate the parameter of the distribution we assumed. Since the underlying rate of emission was assumed to be constant, it was assumed that the emissions followed a Poisson distribution. In fact, for this very reason - that the number of emissions per unit time fluctuate randomly, but there is an underlying constant rate - the Poisson distribution is often used to model radioactive decay. Recall the conditions for using the Poisson distribution to model the number of events in time (or space) are that:\n\nThe underlying rate of events is constant in time (or space),\nThe number of events that occur in disjoint intervals are independent, and\nThere cannot be multiple events at the same instant.\n\nResearchers observed the radioactive decay of Americium 241 and the consequent emission of alpha particles, recording the time between successive emissions. They recorded 1,207 intervals of 10 seconds each, and counted the number of emissions in each of these intervals.\nThe table below, reproduced from (Rice 2006) shows emission counts \\(n\\) in the first column. In the second column is the number of intervals the researchers observed that had \\(n\\) emissions, for each \\(n\\) listed. For example, there were 28 10-second intervals observed that had 3 emissions each, 56 intervals that had 4 emissions each, etc. To compute the expected count, we need a value for the Poisson rate \\(\\lambda\\). The observed mean emission rate which was the total number of emissions divided by the total amount of time was recorded to be 0.8392 seconds. We use this observed mean emission rate to compute an estimate for \\(\\lambda\\) in the probability mass function of the Poisson distribution. Now, the 1,207 counts are the 1,207 realizations of a Poisson random variable with rate \\(\\lambda\\), where \\(\\lambda\\) is the expected number of emissions in 10 seconds,making our estimate, \\(\\hat{\\lambda} = 0.8392 \\times 10 = 8.392\\).\nFor example, how many intervals do we expect with exactly 3 emissions? Each interval has 4 emissions or not 4 emissions. So the number of intervals out of 1,207 total intervals with exactly 4 emissions is a Binomial random variable, with parameters \\(n = 1207\\), and \\(p = P(\\) exactly 4 emissions\\()\\) = \\(\\displaystyle \\dfrac{\\lambda^k e^{-\\lambda}}{k!} \\approx \\dfrac{\\hat{\\lambda}^k  e^{-\\hat{\\lambda}}}{k!}\\). If we plug in \\(k=4\\) and \\(\\hat{\\lambda} = 8.392\\), we get that \\(p \\approx 0.0468\\). Therefore, the expected number of intervals with exactly 4 emissions in \\(np = 1207\\times 0.0468 = 56.4876\\approx 56.5\\).\nFor the first row, since we are combining intervals with exactly 0 or 1 or 2 counts, the Binomial parameter \\(p\\) is given by \\(P(\\) exactly 0 OR exactly 1 OR exactly 2 emissions \\()\\), so we have to add the probabilities of each of these to get \\(p\\). We can see that the expected counts are not too far off from the observed counts. In chapter 9 we will discuss how to quantify the notion of “not too far off”.\n\nObserved and Expected Interval Counts for \\(n\\) Alpha Particle Emissions\n\n\n\\(n\\)\nObserved Number of Intervals\nExpected Number of Intervals\n\n\n\n\n0-2\n18\n12.2\n\n\n3\n28\n27.0\n\n\n4\n56\n56.5\n\n\n5\n105\n94.9\n\n\n6\n126\n132.7\n\n\n7\n146\n159.1\n\n\n8\n164\n166.9\n\n\n9\n161\n155.6\n\n\n10\n123\n130.6\n\n\n11\n101\n99.7\n\n\n12\n74\n69.7\n\n\n13\n53\n45.0\n\n\n14\n23\n27.0\n\n\n15\n15\n15.1\n\n\n16\n9\n7.9\n\n\n17+\n5\n7.1",
    "crumbs": [
      "Lecture 5: Method of Moments"
    ]
  },
  {
    "objectID": "lectures/lecture-5.html#parameter-estimation",
    "href": "lectures/lecture-5.html#parameter-estimation",
    "title": "Parameter Estimation: Method of Moments",
    "section": "Parameter Estimation",
    "text": "Parameter Estimation\n\nSuppose our population is some parametric distribution with pmf or pdf \\(f(x \\vert \\theta)\\), where \\(\\theta\\) is the unknown parameter that we want to estimate.\nWe obtain an IID sample \\(X_1, X_2, \\ldots, X_n\\) from this distribution, so \\(X_i \\sim (x \\vert \\theta)\\).\nThe joint pmf or pdf of \\(X_1, X_2, \\ldots, X_n\\) is given by \\(f(x_1, x_2, \\ldots, x_n)\\). Because this probability depends on \\(\\theta\\), we write the pdf (or pmf, as the case may be), as \\(f(x_1, x_2, \\ldots, x_n \\vert \\theta)\\).\nFor simplicity, let’s assume that we have a discrete distribution, so that\n\n\\[\n\\begin{align*}\nf(x_1, x_2, \\ldots, x_n \\vert \\theta) &= P(X_1 = x_1, X_2 = x_2, \\ldots, X_n = x_n)\\\\\n        &= P(X_1 = x_1)P(X_2 = x_2)\\ldots P(X_n = x_n)\\\\\n        &= f(x_1\\vert \\theta)f(x_2\\vert \\theta)\\ldots f(x_n\\vert \\theta)\\\\\n        &= \\prod_{i=1}^n f(x_i\\vert \\theta)\n\\end{align*}\n\\] - Any estimator of \\(\\theta\\) will be a function of the sample \\(X_1, X_2, \\ldots, X_n\\), which means that the estimator will itself be a random variable. Therefore it will have a probability distribution.\n\nJust like in chapter 7, we call the estimator \\(\\hat{\\theta}\\), and its distribution is called the sampling distribution of \\(\\hat{\\theta}\\).\nWe will need to approximate this distribution, since we need an idea of the error of our estimator, which is governed by its standard error \\(SE(\\hat{\\theta})\\), that is, we denote the square root of \\(\\mathrm{Var}(\\hat{\\theta})\\) by \\(SE(\\hat{\\theta})\\).\nWe will study the following two methods:\n\n\nMethod of moments\nMaximum Likelihood Estimation\n\n\nWe would like to minimize the standard error of our estimator, so we will choose the estimator whose distribution is most concentrated about the true value \\(\\theta\\). That is, we will choose (from among the unbiased estimators) the estimator with the smallest standard error.",
    "crumbs": [
      "Lecture 5: Method of Moments"
    ]
  },
  {
    "objectID": "lectures/lecture-5.html#method-of-moments",
    "href": "lectures/lecture-5.html#method-of-moments",
    "title": "Parameter Estimation: Method of Moments",
    "section": "Method of Moments",
    "text": "Method of Moments\nLet \\(\\mu_k\\) denote the \\(k\\)th moment of the random variable \\(X\\). That is, \\(\\mu_k = E(X^k)\\). The first moment is the mean:\n\\[\n\\mu_1 = E(X).\n\\]\nThe second moment isn’t the variance, but we can get the variance from the first and second moments: \\[\n\\mu_2 = E(X^2) \\Rightarrow \\mathrm{Var}(X) = \\mu_2 - \\mu_1^2\n\\]\nNow, suppose we have an IID random sample \\(X_1, X_2, \\ldots, X_n\\). Define the \\(k\\)th sample moment \\(\\hat{\\mu}_k\\) by \\[\n\\hat{\\mu}_k = \\frac{1}{n} \\sum_{i =1 }^n X_i^k\n\\] For example, \\(\\hat{\\mu}_1\\) is the sample mean \\(\\overline{X}\\). We can use \\(\\hat{\\mu}_k\\) as an estimate for \\(\\mu_k = E(X^k) = E(X^k \\vert \\theta)\\). The method of moments estimates parameters by finding expressions for them in terms of the moments of the lowest possible order, and then plugging in the sample moments into the expression. We usually need as many moments as there are unknown parameter values.\nThere are 3 steps to this method:\n\nFind the moments \\(E(X^k)\\).\nSolve for \\(\\theta\\) in terms of the moments, that is get an expression that looks like \\(\\theta = h(\\mu_1, \\mu_2, \\ldots, \\mu_k)\\).\nPlug in the sample moments to get \\(\\hat{\\theta}\\), so we get \\(\\hat{\\theta} = h(\\hat{\\mu}_1, \\hat{\\mu}_2, \\ldots, \\hat{\\mu}_k)\\)\n\n\nExamples\nExample 1\n\\(X_1, X_2, \\ldots, X_n \\sim Bernoulli(p)\\)\nSo here, \\(\\theta = p\\)\n\n\nCheck your answer!\n\nStep 1: Find the moments. Note that we have just one parameter, so the first moment should suffice.\n\\(E(X_i) = p = \\theta\\).\nStep 2: Therefore \\(\\theta = \\mu_1\\) and we don’t need any more moments. Now $_1 = = .\nStep 3: $ = _1 = .\n/details&gt;\nExample 2\n\\(X_1, X_2, \\ldots, X_n \\sim Exponential(\\lambda)\\).\nStep 1. \\(\\mu_1 = E(X_i) = \\frac{1}{\\lambda}\\)\nStep 2: Solve for \\(\\lambda\\)\n\\(\\lambda = \\dfrac{1}{\\mu_1} \\Rightarrow \\hat{\\lambda} = \\dfrac{1}{\\hat{\\mu}_1} = \\dfrac{1}{\\overline{X}}\\)\n\n[Rice (2006); Wasserman (2004); Pimentel (2024);]",
    "crumbs": [
      "Lecture 5: Method of Moments"
    ]
  },
  {
    "objectID": "lectures/lecture-5.html#references",
    "href": "lectures/lecture-5.html#references",
    "title": "Parameter Estimation: Method of Moments",
    "section": "References",
    "text": "References\n\n\nPimentel, Sam. 2024. “STAT 135 Lecture Slides.” Lecture slides (shared privately).\n\n\nRice, John A. 2006. Mathematical Statistics and Data Analysis. 3rd ed. Duxbury Press.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. New York: Springer.",
    "crumbs": [
      "Lecture 5: Method of Moments"
    ]
  },
  {
    "objectID": "lectures/lecture-8.html",
    "href": "lectures/lecture-8.html",
    "title": "Computing Standard Errors of MoM Estimators: Delta Method and Bootstrap Methods",
    "section": "",
    "text": "In the last lecture, we discussed how to compute the standard error of the method of moments estimator when it is a linear function of the first sample moment, which is the sample mean. In this case, computing the standard error is straightforward, as the CLT applies to linear functions of the sample mean. This means that the estimator will be approximately Normal for a large enough sample of IID random variables from the distribution.\nJust to recap what we discussed in the last lecture, adding a bit more detail for the Poisson case: first we have to derive the standard error of our estimator. Note that this is a constant. Next we use our standard method of estimating the standard error: we plug in the estimated values of the parameters. This gives us the estimated standard error of the method of moments estimator.\nExample Let \\(X_1, \\ldots, X_n\\) be an IID random sample from a Poisson(\\(\\lambda\\)) distribution. Since \\(E(X_i) = \\operatorname{Var}(X_i)= \\mu_1 = \\lambda\\), this means that the method of moments estimator \\(\\hat{\\lambda}_n = \\overline{X}_n\\).\nThis makes it easy to compute the standard error of our estimator. Note that \\[\n\\operatorname{Var}(\\hat{\\lambda}_n) = \\operatorname{Var}(\\overline{X}_n) = \\frac{\\sigma^2}{n} = \\frac{\\lambda}{n}.\n\\] Why is \\(\\operatorname{Var}(\\overline{X}_n) = \\dfrac{\\sigma^2}{n}\\)?\n\n\nCheck your answer\n\n\\(X_i \\sim Poisson(\\lambda)\\) for \\(i = 1, 2, \\ldots, n\\), so we know that the mean and variance of each \\(X_i\\) is \\(\\lambda\\). This means that the variance of the sum of all the \\(X_i\\) is \\(n\\lambda\\), since they are independent. Therefore, the variance of the sample mean is \\(\\lambda/n\\): \\[\n\\operatorname{Var}(\\overline{X}_n) = \\operatorname{Var}\\left(\\frac{1}{n}\\sum_{i=1}^\\infty X_i\\right) = \\frac{1}{n^2}\\left(\\sum_{i=1}^\\infty\\operatorname{Var} (X_i)\\right) = \\frac{n \\sigma^2}{n^2} = \\frac{\\lambda}{n}.\n\\]\n\nThis implies that the standard error of the estimator \\(\\hat{\\lambda}_n = \\overline{X}_n\\) is given by \\(\\displaystyle \\sqrt{\\frac{\\lambda}{n}}\\), and by the central limit theorem, \\(\\hat{\\lambda}_n\\) is approximately normally distributed for large \\(n\\).\n\\[\n\\hat{\\lambda}_n \\approx \\mathcal{N}(\\lambda, \\frac{\\lambda}{n}).\n\\]\nRemember that \\(SE(\\hat{\\lambda}_n)\\) is a constant. But we can estimate it with our usual trick of using our estimate of \\(\\lambda\\). We get that the estimated standard error of the method of moments estimator is given by: \\[\n\\hat{SE}(\\hat{\\lambda}_n) = \\sqrt{\\frac{\\hat{\\lambda}_n}{n}}.\n\\] The hat on the SE above reminds us that this is not a constant, but a quantity that depends on the sample.",
    "crumbs": [
      "Lecture 8: Computing Standard Errors, continued"
    ]
  },
  {
    "objectID": "lectures/lecture-8.html#introduction-and-recap-of-the-linear-case",
    "href": "lectures/lecture-8.html#introduction-and-recap-of-the-linear-case",
    "title": "Computing Standard Errors of MoM Estimators: Delta Method and Bootstrap Methods",
    "section": "",
    "text": "In the last lecture, we discussed how to compute the standard error of the method of moments estimator when it is a linear function of the first sample moment, which is the sample mean. In this case, computing the standard error is straightforward, as the CLT applies to linear functions of the sample mean. This means that the estimator will be approximately Normal for a large enough sample of IID random variables from the distribution.\nJust to recap what we discussed in the last lecture, adding a bit more detail for the Poisson case: first we have to derive the standard error of our estimator. Note that this is a constant. Next we use our standard method of estimating the standard error: we plug in the estimated values of the parameters. This gives us the estimated standard error of the method of moments estimator.\nExample Let \\(X_1, \\ldots, X_n\\) be an IID random sample from a Poisson(\\(\\lambda\\)) distribution. Since \\(E(X_i) = \\operatorname{Var}(X_i)= \\mu_1 = \\lambda\\), this means that the method of moments estimator \\(\\hat{\\lambda}_n = \\overline{X}_n\\).\nThis makes it easy to compute the standard error of our estimator. Note that \\[\n\\operatorname{Var}(\\hat{\\lambda}_n) = \\operatorname{Var}(\\overline{X}_n) = \\frac{\\sigma^2}{n} = \\frac{\\lambda}{n}.\n\\] Why is \\(\\operatorname{Var}(\\overline{X}_n) = \\dfrac{\\sigma^2}{n}\\)?\n\n\nCheck your answer\n\n\\(X_i \\sim Poisson(\\lambda)\\) for \\(i = 1, 2, \\ldots, n\\), so we know that the mean and variance of each \\(X_i\\) is \\(\\lambda\\). This means that the variance of the sum of all the \\(X_i\\) is \\(n\\lambda\\), since they are independent. Therefore, the variance of the sample mean is \\(\\lambda/n\\): \\[\n\\operatorname{Var}(\\overline{X}_n) = \\operatorname{Var}\\left(\\frac{1}{n}\\sum_{i=1}^\\infty X_i\\right) = \\frac{1}{n^2}\\left(\\sum_{i=1}^\\infty\\operatorname{Var} (X_i)\\right) = \\frac{n \\sigma^2}{n^2} = \\frac{\\lambda}{n}.\n\\]\n\nThis implies that the standard error of the estimator \\(\\hat{\\lambda}_n = \\overline{X}_n\\) is given by \\(\\displaystyle \\sqrt{\\frac{\\lambda}{n}}\\), and by the central limit theorem, \\(\\hat{\\lambda}_n\\) is approximately normally distributed for large \\(n\\).\n\\[\n\\hat{\\lambda}_n \\approx \\mathcal{N}(\\lambda, \\frac{\\lambda}{n}).\n\\]\nRemember that \\(SE(\\hat{\\lambda}_n)\\) is a constant. But we can estimate it with our usual trick of using our estimate of \\(\\lambda\\). We get that the estimated standard error of the method of moments estimator is given by: \\[\n\\hat{SE}(\\hat{\\lambda}_n) = \\sqrt{\\frac{\\hat{\\lambda}_n}{n}}.\n\\] The hat on the SE above reminds us that this is not a constant, but a quantity that depends on the sample.",
    "crumbs": [
      "Lecture 8: Computing Standard Errors, continued"
    ]
  },
  {
    "objectID": "lectures/lecture-8.html#hattheta-is-a-nonlinear-function-of-the-sample-mean",
    "href": "lectures/lecture-8.html#hattheta-is-a-nonlinear-function-of-the-sample-mean",
    "title": "Computing Standard Errors of MoM Estimators: Delta Method and Bootstrap Methods",
    "section": "\\(\\hat{\\theta}\\) is a nonlinear function of the sample mean",
    "text": "\\(\\hat{\\theta}\\) is a nonlinear function of the sample mean\nThe method used above is not going to work if the estimator \\(\\hat{\\theta}\\) is a nonlinear function of the sample mean, since the CLT will not apply. We need another way to figure out the standard error. As mentioned in the previous chapter, we will use a standard statistical technique called the delta method, in which, when “confronted with a nonlinear problem that we cannot solve, we linearize”.(Rice 2006)\nExample Recall that the exponential distribution with rate \\(\\lambda\\) has mean and variance \\(\\dfrac{1}{\\lambda}\\) and \\(\\dfrac{1}{\\lambda^2}\\), respectively. In this case, the estimator \\(\\hat\\lambda_n = \\dfrac{1}{\\overline{X}_n}\\), that is, it is the reciprocal of the sample mean.So even though we have a very good idea of the mean and variance of the sample first moment (that is, the sample mean), it is not helpful as we cannot use it directly to compute the moments of \\(\\hat\\lambda_n\\).\n\nThe delta method1\nSuppose we have a random variable \\(X\\) with known mean \\(\\mu_X\\) and variance \\(\\sigma_X^2\\), but we are interested in a different random variable \\(Y = g(X)\\) where \\(g\\) is not a linear function of \\(X\\), and therefore \\(E(Y) = E(g(X)) \\ne g(E(X))\\).\nThe main idea behind the delta method is that we use a Taylor series expansion of \\(g\\) about \\(\\mu_X\\) and linearize \\(Y = g(X)\\), and once we do that, we can approximate the mean and variance of \\(Y\\).\nLet’s do the first order expansion: \\[\nY = g(\\mu_X) + (X-\\mu_X)g'(\\mu_X) + R.\n\\]\n\\(R\\) is the remainder term that will be negligible for large \\(n\\) because of higher powers of \\((X-\\mu_X)\\).\nThis implies that \\(\\displaystyle Y \\approx g(\\mu_X) + (X-\\mu_X)g'(\\mu_X)\\), and so taking expectations on both sides, we get: \\[\nY \\approx g(\\mu_X) + (X-\\mu_X)g'(\\mu_X)  \\Rightarrow E(Y) \\approx E\\left[g(\\mu_X)\\right]\n\\]\n(Since \\(E(X-\\mu_X) = 0\\).) This method (of linearizing \\(Y\\) in order to approximate its mean and variance) is called the delta method because it comes from writing \\(\\delta = \\hat{\\theta} - \\theta\\) and then expanding \\(g(\\theta + \\delta)\\) as a function of \\(\\delta\\). (Chihara and Hesterberg 2018)\nWe can also do a second order Taylor’s series expansion to improve our approximation: \\[\nY = g(X) \\approx g(\\mu_X) + (X-\\mu_X)g'(\\mu_X) + \\dfrac{1}{2}(X-\\mu_X)^2 g''(\\mu_X)\n\\] Taking expectations gives us that \\[\nE(Y) \\approx g(\\mu_X) + \\dfrac{1}{2} \\sigma_X^2 g''(\\mu_X).\n\\]\nHow good the linear approximation is depends on how nonlinear \\(g\\) is in a neighborhood of \\(\\mu_X\\), and on the variance of \\(X\\).\nGoing back to the first order approximation, we have that \\(Y \\approx g(\\mu_X) + (X-\\mu_X)g'(\\mu_X)\\). Squaring both sides gives: \\[\nY^2 \\approx \\left(g(\\mu_X)\\right)^2 + \\left(g'(\\mu_X)\\right)^2(X - \\mu_X)^2 + 2g'(\\mu_X)(X-\\mu_X)\n\\] Again, since \\(E(X-\\mu_X) = 0\\), we get that \\[\n\\operatorname{Var}(Y) \\approx \\left[g'(\\mu_X)\\right]^2 \\sigma_X^2.\n\\] Note that we can apply the delta method in a multivariate setting, but here we will only consider univariate functions.\nAnd now, we have the mean and the variance (approximately) of \\(g(X)\\), and we are ready for its asymptotic distribution.\n\nTheorem\nSuppose we have a sequence of random variables \\(\\{U_n\\}\\) that is asymptotically normal,that is, there exist constants \\(\\theta, \\sigma\\), where \\(\\sigma &gt; 0\\), such that \\[\n\\sqrt{n} \\left(\\dfrac{U_n -\\theta}{\\sigma} \\right)\\overset{D} \\longrightarrow \\mathcal{N}(0,1).\n\\] That is, the distribution of \\(U_n\\), suitably standardized, converges to a standard normal distribution. Then, for any differentiable function \\(g\\), such that \\(\\lvert g'(\\theta)\\rvert \\ne 0\\), we have: \\[\n\\sqrt{n} \\left(\\dfrac{g(U_n) -g(\\theta)}{\\lvert g'(\\theta)\\rvert \\sigma} \\right)\\overset{D} \\longrightarrow \\mathcal{N}(0,1).\n\\] That is, \\(g(U_n)\\) is also approximately normal for large \\(n\\): \\[\ng(U_n) \\approx \\mathcal{N}\\left(g(\\theta), \\frac{\\lvert g'(\\theta)\\rvert^2 \\sigma^2}{n}\\right)\n\\]\nProof sketch\nUsing Taylor expansion (or the delta method) of \\(g\\) about \\(\\theta\\), we have that \\[\ng(U_n) = g(\\theta) + (U_n - \\theta)g'(\\theta) + R,\n\\] where \\(R\\) is a remainder term that goes to \\(0\\) as \\(n \\rightarrow \\infty\\).\nSubracting \\(g(\\theta)\\) from both sides and multiplying both sides by \\(\\sqrt{n}\\) we get: \\[\n\\sqrt{n}\\left[g(U_n) - g(\\theta)\\right] = \\sqrt{n} (U_n - \\theta)g'(\\theta) + R\n\\] Notice that multiplying the remainder term by \\(\\sqrt{n}\\) makes no difference, it will still go to \\(0\\) as \\(n \\rightarrow \\infty\\), so we just continue to write it as \\(R\\).\nWe know that \\(\\sqrt{n} (U_n - \\theta)/\\sigma\\) is approximately standard normal(that is \\(\\sqrt{n} (U_n - \\theta)/\\sigma \\approx \\mathcal{N}(0, 1))\\) which implies that \\(\\sqrt{n} (U_n - \\theta)\\) is approximately normal with mean \\(0\\) and variance \\((\\sigma\\cdot g'(\\theta))^2\\). Therefore the lefthand side also must be approximately normal with the same parameters: \\[\n\\sqrt{n}\\left[g(U_n) - g(\\theta)\\right] \\approx \\mathcal{N}\\left(0, [\\sigma\\cdot g'(\\theta)]^2\\right).\n\\]\nwhich gives us the result of the theorem (by dividing by \\(\\lvert \\sigma\\cdot g'(\\theta)\\rvert\\)).\n\n\n\nBack to our sample mean and MoM estimator\nInstead of \\(\\{U_n\\}\\), we have our sequence of sample means \\(\\{\\overline{X}_n\\}\\), and \\(g(\\{\\overline{X}_n\\}) = \\hat{\\theta}\\). By the delta method, we have that \\[\n\\sqrt{n}\\left(\\frac{\\overline{X}_n - g(\\mu)}{\\lvert g'(\\mu)\\rvert\\sigma}\\right)\\overset{D}{\\longrightarrow}\\mathcal{N}(0,1).\n\\] This implies that \\[\ng(\\overline{X}_n) \\approx \\mathcal{N}\\left(g(\\mu), \\frac{(g'(\\mu))^2\\sigma^2}{n}\\right)\n\\] Note that \\(\\mu\\) and \\(\\sigma\\) are unknown constants, and so we can estimate the parameters of this asymptotic normal distribution with our estimate for \\(\\theta\\): \\[\n\\hat{\\theta} = g(\\hat{\\mu}_1),\n\\] and estimate \\(\\sigma^2\\) by the sample variance \\(S^2\\). Thus we conclude that \\[\n\\hat{\\theta}_{MoM} = g(\\hat{\\mu}_1) \\approx \\mathcal{N}\\left(\\theta, \\frac{(g'(\\hat{\\mu}_1))^2 S^2}{n}\\right).\n\\]",
    "crumbs": [
      "Lecture 8: Computing Standard Errors, continued"
    ]
  },
  {
    "objectID": "lectures/lecture-8.html#hattheta-is-more-complex",
    "href": "lectures/lecture-8.html#hattheta-is-more-complex",
    "title": "Computing Standard Errors of MoM Estimators: Delta Method and Bootstrap Methods",
    "section": "\\(\\hat{\\theta}\\) is more complex",
    "text": "\\(\\hat{\\theta}\\) is more complex\nIf \\(\\hat{\\theta}\\) is more complex, such as when we estimate the parameters of the Gamma distribution, \\(\\alpha\\) and \\(\\lambda\\). Recall their method of moments estimators2: \\[\n\\hat\\alpha = \\frac{\\overline{X}_n^2}{S^2} \\quad \\quad \\quad \\quad  \\hat \\lambda = \\frac{\\overline{X}_n}{S^2}\n\\] If we want the sampling distributions of these estimators, none of the methods we have used so far will work, as both \\(\\hat\\alpha\\) and \\(\\hat\\lambda\\) are complicated functions of the sample mean.So we will use our computers to construct bootstrap distributions of these quantities.\n\nThe Bootstrap\nThe bootstrap is a resampling method for estimating measures of accuracy (such as variance or confidence intervals) for the estimator when obtaining them analytically is difficult. Resampling methods have become extremely common and absolutely indispensable in statistics due to the widespread availability of computing power. We use the bootstrap to quantify the uncertainty associated with an estimator.\nWe can view the sample as the population in two ways, leading to two different kinds of bootstrap.\n\nWe know the distribution of the population is from a particular parametric family of distributions. We estimate the parameters of that distribution, and then resample from the estimated distribution, using these samples to build a probability distribution for our parameter estimator. This method is called the parametric bootstrap. This is a more logical fit for the method of moments estimators.\nWe don’t know the population distribution, and don’t know if a parametric family is appropriate. We just resample from the sample. This is called a nonparametric bootstrap as we make no assumption about the distribution, and can be used in a very wide variety of situations.\n\nThe basic idea of the bootstrap is to use the empirical distribution of the sample as an approximating distribution of the population when the sample is large. That is, we use the sample as a stand-in for the population, and resample from it.\nThe name comes from the phrase, “pull yourself up by your bootstraps” which means to succeed by your own cleverness/hard work - without getting help from others; here we estimating something tricky by cleverly reusing the same sample we started with.\n\n\n\n\n\n\nCaution\n\n\n\nBootstrap works only if the sample is large enough to accurately represent the population distribution.\n\n\nThe bootstrap procedure to approximate the sampling distribution for \\(\\hat\\theta\\), given a sample \\(X_1, \\ldots, X_n\\) would be:\n\nCompute the observed value of \\(\\hat\\theta\\)\nLet \\(B\\) be some large number (such as 5000).\nFor each \\(i\\), \\(i = 1, 2, \\ldots, B\\), do the following steps:\n\n\nGet a new sample of the same size, n (either by resampling from the original sample, or by using \\(\\hat\\theta\\) to generate a sample from the assumed distribution).\nCompute the observed value of the estimator for this new sample, and call it \\(\\hat\\theta_i^*\\).\nRepeat steps (i) and (ii) to get \\(\\hat\\theta_1^*, \\hat\\theta_2^*, \\ldots, \\hat\\theta_B^*\\)\nEstimate the variance as \\(\\displaystyle \\dfrac{1}{B} \\sum_{i=1}^B \\left(\\hat\\theta_i^*-\\overline{\\hat\\theta^*}\\right)^2\\), where \\(\\overline{\\hat\\theta^*} = \\displaystyle \\dfrac{1}{B} \\sum_{i=1}^B\\hat\\theta_i^*\\) is the mean of \\(\\hat\\theta_1^*, \\hat\\theta_2^*, \\ldots, \\hat\\theta_B^*\\). The bootstrap SE estimate, denoted \\(s_{\\mathrm{boot}}\\) will be the square root of the bootstrap estimate of the variance.\nThe bootstrap bias estimate will be \\(\\overline{\\hat\\theta^*}-\\hat\\theta\\).\n\nYou could also plot the histogram of these values to get a visualization of the distribution.\n\n\nConfidence intervals using the bootstrap\nThere are a number of ways to using the bootstrap to compute confidence intervals. Here are three ways of finding a \\(100(1-\\alpha)\\%\\) confidence interval (\\(0&lt;\\alpha&lt;1\\)). For a 95% confidence interval, \\(\\alpha = 0.05\\).\n\nBootstrap percentile interval\n\nThe confidence interval is given by \\((q_{\\alpha/2}, q_{1-\\alpha/2})\\), where \\(q_{\\alpha/2}\\) is the \\(\\alpha/2\\)th quantile of the bootstrap distribution and \\(q_{1-\\alpha/2}\\) is the \\((1-\\alpha/2)\\)th quantile of the bootstrap distribution. Since \\(P(\\hat\\theta^* \\le q_{\\alpha/2}) = \\alpha/2\\), and \\(P(\\hat\\theta^* \\le q_{1-\\alpha/2}) = 1-\\alpha/2\\), the area captured in the middle is \\(1-\\alpha\\), which is what we need. This is usually fine unless the distribution is very skewed.\n\nBootstrap basic (pivotal) interval\n\nThis is sometimes called the reverse percentile interval and is the one defined in your textbook. We can use the bootstrap to compute approximate confidence intervals for the true value of \\(\\theta\\). Suppose the true value of the parameter \\(\\theta\\) is given by \\(\\theta_0\\).\nDefine \\(\\Delta = \\hat\\theta - \\theta_0\\), and suppose we know the distribution of \\(\\Delta\\). This means that we know the quantiles of this distribution, and if we want to capture the middle 95% of the values, we can use the 2.5th percentile and 97.5th percentiles to do this. Denote the 2.5th percentile by \\(q_{0.025}\\) and the 97.5th percentile by \\(q_{0.975}\\).\nThis means that \\(P(\\Delta \\le q_{0.025}) = 0.025\\) and \\(P(\\Delta \\le q_{0.975}) = 0.975\\)\nThen we have that: \\[\nP(q_{0.025}\\le \\Delta \\le q_{0.975}) = 0.95 \\Rightarrow P(q_{0.025}\\le \\hat\\theta - \\theta_0 \\le q_{0.975}) = 0.95\n\\] We can manipulate the inequalities to isolate \\(\\theta_0\\) in the center: \\[\n\\begin{align}\n0.95 &= P(q_{0.025}\\le \\hat\\theta - \\theta_0 \\le q_{0.975})\\\\\n      &=  P(q_{0.025} -\\hat\\theta \\le  - \\theta_0 \\le q_{0.975} -\\hat\\theta)\\\\\n      &= P(- q_{0.025} + \\hat\\theta \\ge   \\theta_0 \\ge - q_{0.975} + \\hat\\theta)\\\\\n      &= P( \\hat\\theta - q_{0.975}\\le \\theta_0 \\le  \\hat\\theta -q_{0.025}) \\\\\n\\end{align}\n\\] This gives us a 95% confidence interval for \\(\\theta_0\\). There is nothing special about 95%, except that it is commonly used as a confidence level. We could use any confidence level, say \\(1-\\alpha\\). (When we use a 95% CI, \\(\\alpha\\) is \\(0.05\\).)\nThen, to capture \\(1-\\alpha\\) in the middle, we need the \\(\\dfrac{\\alpha}{2}\\) and \\(1-\\dfrac{\\alpha}{2}\\) quantiles in place of \\(q_{0.025}\\) and \\(q_{0.975}\\) respectively. Denote these quantiles by \\(q_{\\alpha/2}\\) and \\(q_{1-\\alpha/2}\\) We do the manipulation above and get the following: \\[\nP( \\hat\\theta - q_{1-\\alpha/2}\\le \\theta_0 \\le  \\hat\\theta -q_{\\alpha/2}) = 1-\\alpha.\n\\] The only problem of course is that we don’t know the distribution of \\(\\Delta = \\hat\\theta - \\theta_0\\). This is where we can use the bootstrap. We generate many samples (\\(B\\) samples, as mentioned above, where \\(B\\) is large), and compute \\(\\hat\\theta_1^*, \\hat\\theta_2^*, \\ldots, \\hat\\theta_B^*\\) from each sample. Then the distribution of \\(\\hat\\theta -\\theta_0\\) is approximated by the distribution of \\(\\hat\\theta^* - \\hat\\theta\\).\nNote that the quantiles of the approximated \\(\\Delta\\) distribution (using \\(\\hat\\theta^* -\\hat\\theta\\)) are just the quantiles of the \\(\\hat\\theta^*\\) distribution less \\(\\hat\\theta\\). That is, if we let \\(q_\\alpha\\) be the \\(\\alpha\\)th quantile of the \\(\\Delta\\) distribution, and \\(q_\\alpha^*\\) be the \\(\\alpha\\)th quantile of the \\(\\hat\\theta^*\\) distribution, \\(q_\\alpha = q_\\alpha^* - \\hat\\theta\\). Substituting this into our confidence interval above, we get that the basic \\(100(1-\\alpha)\\%\\) confidence interval for \\(\\theta_0\\) can be written as \\((2\\hat\\theta - q_{1-\\alpha/2}^*,2\\hat\\theta - q_{\\alpha/2}^* )\\).\n\nThe Normal interval\n\nThis is the simplest, and will be fine if the distribution looks approximately normal. It is simply given by \\(\\hat\\theta \\pm z_{\\alpha/2}\\times  s_{\\mathrm{boot}}\\), where \\(s_{\\mathrm{boot}}\\) is the bootstrap estimate of the standard error of \\(\\theta\\).\n\n\nExample of rainfall data from the text (Rice 2006)\n# the data was read in using read_csv\n# putting all of these datasets together \n# using bind_rows from dplyr\n# similar to rbind\n\nillinois_rain &lt;- bind_rows(\n  illinois_60 %&gt;% mutate(year = \"1960\"),\n  illinois_61 %&gt;% mutate(year = \"1961\"),\n  illinois_62 %&gt;% mutate(year = \"1962\"),\n  illinois_63 %&gt;% mutate(year = \"1963\"),\n  illinois_64 %&gt;% mutate(year = \"1964\")\n)\n\n\nCode\n### illiois_rain was a pain to type.\nil_rain &lt;- illinois_rain\n\n### Just cleaning up a bit\nil_rain &lt;- il_rain |&gt; \n  rename(rain_inches =X1)\nil_rain &lt;- il_rain |&gt; \n  mutate(year = as.factor(year))\n\n\nA snapshot of the data:\n\n\nCode\nglimpse(il_rain)\n\n\nRows: 227\nColumns: 2\n$ rain_inches &lt;dbl&gt; 0.020, 0.001, 0.001, 0.120, 0.080, 0.420, 1.720, 0.050, 0.…\n$ year        &lt;fct&gt; 1960, 1960, 1960, 1960, 1960, 1960, 1960, 1960, 1960, 1960…\n\n\nComputing sample moments and observed values of the method of moments estimators:\n\n\nCode\nil_moments &lt;- il_rain |&gt; \n  summarise(\n    mu1 = mean(rain_inches, na.rm = TRUE),\n    mu2 = mean(rain_inches^2, na.rm = TRUE),\n    sigma_hat_sq = mu2-mu1^2,\n    lambda = mu1/sigma_hat_sq,\n    alpha = mu1^2/sigma_hat_sq\n  )\n\nil_moments\n\n\n# A tibble: 1 × 5\n    mu1   mu2 sigma_hat_sq lambda alpha\n  &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 0.224 0.184        0.133   1.68 0.378\n\n\nPulling the observed estimator values out of the data frame il_moments and saving the numeric values.\n\n\nCode\n# pull() pulls the vector out of the data frame, similar to $ in base R\n\nobs_alpha &lt;- pull(il_moments, alpha)\nobs_lambda &lt;- pull(il_moments, lambda)\n\nprint(c(obs_alpha = obs_alpha, obs_lambda = obs_lambda))\n\n\n obs_alpha obs_lambda \n 0.3779155  1.6841748 \n\n\nNow for a plot of the data and an overlaid Gamma density using our method of moments estimates as parameters to see if it is an appropriate choice for this data.\n\n\nCode\n### plotting the distribution: the histogram overlaid with the density\n\nil_rain |&gt; \n  ggplot(mapping =  aes(x = rain_inches)) +\n  geom_histogram(aes(y = after_stat(density)), color = \"grey\") +\n  stat_function(fun = dgamma, args = list(shape = obs_alpha, rate = obs_lambda)) +\n  ylim(0,6)+\n  labs(\n    title = \"Rainfall per storm with Gamma (MoM) fit\",\n    x = \"Rainfall per storm\",\n    y = \"Density\"\n  )\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_function()`).\n\n\n\n\n\n\n\n\n\nFirst, we will do the parametric bootstrap, with \\(B = 10,000\\). Our sample size is 227, so that will be the size of each sample we generate.\nIt is better to write a function that you can then put into replicate(). We input a vector and return a list that contains the MoM estimators.\n\n\nCode\n# function to compute alpha and lambda given a vector\n# note that we need to input a VECTOR not a df.\n\ngamma_mom &lt;- function(x) {\n  mu1 &lt;-  mean(x, na.rm = TRUE)\n  mu2 &lt;- mean(x^2, na.rm = TRUE)\n  sigma_hat_sq &lt;-  mu2-mu1^2\n  lambda &lt;-  mu1/sigma_hat_sq\n  alpha &lt;-  mu1^2/sigma_hat_sq\n  return(c(alpha = alpha , lambda = lambda))\n}\n\n\nLet’s test our function gamma_mom against the observed values that we computed earlier. Note that theta_hat below is a vector\n\n\nCode\ntheta_hat &lt;- gamma_mom(pull(il_rain, rain_inches))\ncat(\"does gamma_mom give the correct values\\n\")\n\n\ndoes gamma_mom give the correct values\n\n\nCode\nobs_alpha == theta_hat[\"alpha\"]\n\n\nalpha \n TRUE \n\n\nCode\nobs_lambda == theta_hat[\"lambda\"]\n\n\nlambda \n  TRUE \n\n\nNow the next bit of code, which you can read, generates the bootstrap values, and then stores it as a data frame rather than a matrix.\n\n\nCode\nboot_mat &lt;- replicate(B, gamma_mom(rgamma(n, shape = obs_alpha, rate = obs_lambda)))\n\n#' In order to plot the distributions as histograms, we need a data frame,\n#'  so let's transpose the matrix boot_mat and make sure it is still a data frame\n#'  since that is what we need to input into ggplot.\n\nboot_df &lt;- as.data.frame(t(boot_mat))\n\n\nWe check the first few rows of our data frame\n\n\nCode\nhead(boot_df)\n\n\n      alpha   lambda\n1 0.3582914 1.622130\n2 0.3108627 1.802807\n3 0.3432051 1.457107\n4 0.4876132 1.977671\n5 0.4973687 2.090700\n6 0.3600022 1.929336\n\n\nComputing the 0.025th and 0.975th quantiles of the distribution for both alpha and lambda:\n\n\nCode\n## finding the quantiles of the distribution\n\nalpha_lq &lt;- quantile(boot_df$alpha, probs = 0.025, na.rm = TRUE)\nalpha_uq &lt;- quantile(boot_df$alpha, probs = 0.975, na.rm = TRUE)\n\nlambda_lq &lt;- quantile(boot_df$lambda, probs = 0.025, na.rm = TRUE)\nlambda_uq &lt;- quantile(boot_df$lambda, probs = 0.975, na.rm = TRUE)\n\ncat(\"alpha 0.025th quantile =\", alpha_lq, \"\\n\")\n\n\nalpha 0.025th quantile = 0.2722415 \n\n\nCode\ncat(\"alpha 0.975th quantile =\", alpha_uq, \"\\n\")\n\n\nalpha 0.975th quantile = 0.5255163 \n\n\nCode\ncat(\"lambda 0.025th quantile =\", lambda_lq, \"\\n\")\n\n\nlambda 0.025th quantile = 1.156345 \n\n\nCode\ncat(\"lambda 0.975th quantile =\", lambda_uq, \"\\n\")       \n\n\nlambda 0.975th quantile = 2.528419 \n\n\nHere is the percentile 95% confidence interval for \\(\\alpha\\)\n\n\nCode\n## percentile confidence intervals\nalpha_ci &lt;- c(alpha_lq, alpha_uq)\n\ncat(\"A percentile 95% CI for alpha is \", alpha_ci)\n\n\nA percentile 95% CI for alpha is  0.2722415 0.5255163\n\n\nHere is the percentile 95% confidence interval for \\(\\lambda\\)\n\n\nCode\n## percentile confidence intervals\nlambda_ci &lt;- c(lambda_lq, lambda_uq)\n\ncat(\"A percentile 95% CI for lambda is \", lambda_ci)\n\n\nA percentile 95% CI for lambda is  1.156345 2.528419\n\n\nHere is the basic or reverse confidence interval for alpha\n\n\nCode\n## basic confidence intervals\n\nalpha_ci_basic &lt;- c(2*obs_alpha -alpha_uq, 2*obs_alpha -alpha_lq )\ncat(\"A basic 95% CI for alpha is \", alpha_ci_basic)\n\n\nA basic 95% CI for alpha is  0.2303147 0.4835894\n\n\nHere is the basic or reverse confidence interval for lambda\n\n\nCode\nlambda_ci_basic &lt;- c(2*obs_lambda -lambda_uq, 2*obs_lambda -lambda_lq )\ncat(\"A basic 95% CI for lambda is \", lambda_ci_basic)\n\n\nA basic 95% CI for lambda is  0.8399301 2.212005\n\n\nFinally the graph of the parametric bootstrap distribution for alpha. The dashed vertical lines show the percentile CI and the dotted lines are the basic CI.\n\n\nCode\np1 &lt;-  boot_df |&gt; ggplot(aes(x = alpha)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, color = \"grey\") +\n   geom_vline(xintercept = alpha_ci, linetype = \"dashed\", linewidth = 1) +\n   geom_vline(xintercept = obs_alpha, linewidth = 1.2, color = \"red\") +\n  geom_vline(xintercept = alpha_ci_basic, linetype = \"dotted\", linewidth = 1) +\n  xlim(0.2,0.6)+\n  labs(title = \"Parametric bootstrap distribution of alpha (MoM Estimate)\",\n       x = \"alpha\", y = \"Density\")\np1\n\n\nWarning: Removed 27 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\nThe same figure for lambda:\n\n\nCode\np2 &lt;- boot_df |&gt; ggplot(aes(x = lambda)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, color = \"grey\") +\n   geom_vline(xintercept = lambda_ci, linetype = \"dashed\", linewidth = 1) +\n   geom_vline(xintercept = obs_lambda, linewidth = 1.2, color = \"red\") +\n   geom_vline(xintercept = lambda_ci_basic, linetype = \"dotted\", linewidth = 1) +\n   xlim(0.5, 3) +\n  labs(title = \"Parametric bootstrap distribution of lambda (MoM Estimate)\",\n       x = \"lambda\", y = \"Density\")\n\np2\n\n\nWarning: Removed 12 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\nCode\np3 &lt;- ggplot(boot_np, aes(x = alpha)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, color = \"grey\") +\n  geom_vline(xintercept = alpha_ci_np, linetype = \"dashed\", linewidth = 1) +\n  geom_vline(xintercept = alpha_ci_basic_np, linetype = \"dotted\", linewidth = 1) +\n  geom_vline(xintercept = obs_alpha, linewidth = 1.2, color = \"green\") +\n  xlim(0.2,0.6) +\n  labs(\n    title = \"Nonparametric bootstrap sampling distribution of alpha (MoM)\",\n    x = \"alpha\",\n    y = \"Density\"\n  )\n\np3\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\nCode\np4 &lt;- ggplot(boot_np, aes(x = lambda)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50,color = \"grey\") +\n  geom_vline(xintercept = lambda_ci_np, linetype = \"dashed\", linewidth = 1) +\n  geom_vline(xintercept = lambda_ci_basic_np, linetype = \"dotted\", linewidth = 1) +\n  geom_vline(xintercept = obs_lambda, linewidth = 1.2, color = \"green\") +\n  xlim(0.5, 3) +\n  labs(\n    title = \"Nonparametric bootstrap sampling distribution of lambda (MoM)\",\n    x = \"lambda\",\n    y = \"Density\")\n\np4\n\n\nWarning: Removed 10 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).",
    "crumbs": [
      "Lecture 8: Computing Standard Errors, continued"
    ]
  },
  {
    "objectID": "lectures/lecture-8.html#references",
    "href": "lectures/lecture-8.html#references",
    "title": "Computing Standard Errors of MoM Estimators: Delta Method and Bootstrap Methods",
    "section": "References",
    "text": "References\n\n\nChihara, Laura M., and Tim C. Hesterberg. 2018. Mathematical Statistics with Resampling and r. John Wiley & Sons, Hoboken, NJ.\n\n\nPimentel, Sam. 2024. “STAT 135 Lecture Slides.” Lecture slides (shared privately).\n\n\nRice, John A. 2006. Mathematical Statistics and Data Analysis. 3rd ed. Duxbury Press.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. New York: Springer.",
    "crumbs": [
      "Lecture 8: Computing Standard Errors, continued"
    ]
  },
  {
    "objectID": "lectures/lecture-8.html#footnotes",
    "href": "lectures/lecture-8.html#footnotes",
    "title": "Computing Standard Errors of MoM Estimators: Delta Method and Bootstrap Methods",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is discussed in the textbook (Rice 2006) on page 162, in chapter 4.\n\n\n\n↩︎\nI am using \\(S^2\\) to denote the random variable called sample variance (that estimates the variance), and \\(s^2\\) to denote the realized value of \\(S^2\\). [Rice (2006); Wasserman (2004); Pimentel (2024); Chihara and Hesterberg (2018);]",
    "crumbs": [
      "Lecture 8: Computing Standard Errors, continued"
    ]
  },
  {
    "objectID": "lectures/lecture-3.html",
    "href": "lectures/lecture-3.html",
    "title": "Survey Sampling: Inference",
    "section": "",
    "text": "Inference involves using a sample to compute an estimate of a population parameter, and the population should always be defined in the context in which the results will be applied.\n\nEstimator: The function (or algorithm) that maps sample data to a number.\n\n\nEstimate: The actual observed value after applying the estimator on the sample (observed) data.\n\n\n\n\n\n\nThen of course the question we would have is how good is our estimator and therefore our estimate? We want \\(\\mu\\), and we have the estimate \\(\\hat{\\mu}\\). How close is this estimate to the true value \\(\\mu\\)? We need a measure of goodness of our estimator. Note that our estimator is random. Each time we take a random sample, we will get a different value of the estimate. We want to know on average, what is the error of our estimator? To compute this, we need to consider the sampling distribution of our estimator. This is just a special name for the probability distribution of the estimator, which is a random variable. The randomness of the estimator is rooted in the randomness of the sampling. The spread of the probability distribution, measured by its standard deviation is one of the determinants of the accuracy of our estimator.\n\n\n\n\n\nIf we would hit our target (the population parameter) on average (that means that the expected value of our estimator is the population parameter), then we only need to consider how much our estimator’s sampling distribution spreads about the mean. The tighter the spread (the smaller the standard deviation), the more accurate the estimator. Now, because we are measuring the error of our estimator, we call the square root of its variance the standard error rather than the standard deviation.\nWhat if, though, the expected value of our estimator is not the target parameter? In this case the difference between the expected value of the estimator and the true value of the population parameter will also contribute to the error. Because of this, we use a measure of goodness of our estimate that incorporates both the spread (standard error) and the average distance from the parameter (we call this bias). This measure is called the Mean Squared Error.\n\n\n\nMean Squared Error: The mean squared error is the expected value of the squared difference between the estimator \\(\\hat{\\theta}\\) and the true value of the population parameter \\(\\theta\\). We denoted it by \\(MSE\\): \\[\nMSE = E\\left[\\left(\\hat{\\theta} - \\theta \\right)^2\\right]\n\\]\n\n\nBias: The bias of an estimator is its distance, on average, from the true value of the population parameter: \\[\n\\operatorname{Bias}(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta\n\\] We call an estimator unbiased if the bias is 0, that is if \\(E(\\hat{\\theta}) = \\theta\\).\n\nExercise Show that \\(MSE =  \\text{Variance} + \\text{Bias}^2\\).\n\n\nSolution\n\n\\[\n\\begin{align*}\n\\mathrm{MSE}(\\hat\\theta)\n&= E\\big[(\\hat\\theta - \\theta)^2\\big] \\\\\n&= E\\big(\\hat\\theta ^2\\big) -2 \\theta E\\big(\\hat\\theta\\big) + \\theta^2\\\\\n&= \\mathrm{Var}\\big(\\hat\\theta\\big) +  \\big[E\\big(\\hat\\theta\\big)\\big]^2 -2 \\theta E\\big(\\hat\\theta\\big) + \\theta^2\\\\\n&= \\mathrm{Var}\\big(\\hat\\theta\\big) + \\big[E\\big(\\hat\\theta\\big) - \\theta\\big]^2\\\\\n&= \\mathrm{Var}(\\hat\\theta) + \\big[\\mathrm{Bias}(\\hat\\theta)\\big]^2.\n\\end{align*}\n\\]\n\nHere is a figure from Lohr’s text that shows the difference between low bias, low variance, and low MSE:\n\n\n\nUnbiased archers, precise archers, and accurate archers\n\n\nThis diagram shows that an estimator \\(\\hat{\\theta}\\) is unbiased if \\(E\\big(\\hat{\\theta}\\big) = \\theta\\), it is precise if \\(\\mathrm{Var}(\\hat{\\theta})\\) is small, but for the estimator to be accurate, both these quantities must be small, and therefore the Mean Squared Error (the sum of the squared bias and the variance) must be small, where \\(MSE = E\\big[\\big(\\hat{\\theta} - \\theta\\big)^2\\big]\\).\n\n\n\nRecall that if we let \\(X_1, X_2, \\ldots, X_n\\) are independent and identically distributed random variables (IID), with common expected value \\(\\mu\\) and variance \\(\\sigma^2\\); and \\(\\overline{X}\\) is the sample mean of this sample \\(\\big(\\displaystyle \\overline{X} = \\dfrac{1}{n} \\sum_{i=1}^n X_i\\big)\\), then \\(E(\\overline{X}) = \\mu\\) and \\(\\mathrm{Var}(\\overline{X}) = \\sigma^2/n\\). (Note: You should be able to show this.)\nNow suppose we have a finite population of size \\(N\\), and we take a simple random sample of size \\(n\\) from this population: \\(X_1, X_2, \\ldots, X_n\\). Now the \\(X_i\\) cannot be IID as we are sampling without replacement. It is easily shown (Theorem A on page 206) that the expected value of the sample mean is still \\(\\mu\\), where \\(\\mu\\) is the population mean. What about \\(\\mathrm{Var}(\\overline{X})\\)?\nIt turns out that ( Theorem B on page 208): \\[\n\\mathrm{Var}(\\overline{X}) = \\dfrac{\\sigma^2}{n}\\left( \\dfrac{N-n}{N-1}\\right).\n\\]\n\n\nClick for the proof\n\n\\[\n\\begin{align*}\n\\mathrm{Var}(\\overline{X}) &= \\mathrm{Var}\\left(\\dfrac{1}{n}\\sum_{i = 1}^n X_i\\right)\\\\\n  &= \\dfrac{1}{n^2} \\mathrm{Var}\\left(\\sum_{i = 1}^n X_i\\right), \\: \\text{because }\\mathrm{Var}(aX) = a^2\\mathrm{Var}(X)\\\\\n  &= \\dfrac{1}{n^2}\\mathrm{Cov}\\left(\\sum_{i = 1}^n X_i,\\sum_{j = 1}^n X_j \\right), \\: \\text{because } \\mathrm{Var}(X) = \\mathrm{Cov}(X,X)\\\\\n  &= \\dfrac{1}{n^2}\\left(\\sum_{i = 1}^n \\mathrm{Var}(X_i) + \\sum_{i = 1}^n \\sum_{\\substack{j=1 \\\\ j \\ne i}}^n \\mathrm{Cov}(X_i,X_j)\\right) \\\\\n  &= \\dfrac{1}{n^2} \\left( n\\sigma^2 + n(n-1) \\mathrm{Cov}(X_1, X_2) \\right), \\: \\text{since all } n(n-1) \\text{ pairs will have the same covariance.}\n\\end{align*}\n\\] This computation implies that if we figure out \\(\\mathrm{Cov}(X_1, X_2)\\), we will able to figure out the variance we need. So let’s compute this covariance. Recall that \\(\\mathrm{Cov}(X_1, X_2) = E(X_1 X_2) - E(X_1)E(X_2)\\).\nWe know that the possible values of the \\(X_i\\) are the population values: \\(x_1, x_2, \\ldots, x_N\\). But some of these could be repeated, which can mess up the probability computations. To simplify our computations, we will define new values \\(u_1, u_2, \\ldots, u_m\\) to be the distinct values in the population, \\(m\\) the number of distinct values, and let \\(n_i\\) be the number of times we see the value \\(u_i\\).\nFor example, suppose \\(N = 6\\) and the population values are \\(1, 1, 4, 4, 4, 7\\). Then \\(x_1 = 1 = x_2, x_3 = x_4 = x_5 = 4\\), and \\(x_6 = 7\\). Using the \\(u_i's\\), we have \\(u_1 = 1, u_2 = 4, u_3 = 7\\), and \\(m=3\\). Further, \\(n_1 = 2, n_2 = 3, n_3 = 1\\).\nNow, if \\(X_i\\) is the \\(i\\)th sample value drawn, then \\(X_i\\) is a discrete random variable such that \\(P(X_i = u_i) = \\dfrac{n_i}{N}\\). This is because there are still \\(N\\) total units in the population, and we have just grouped them by value.\nFor example, using the numbers above, \\(P(X_i = 4) = \\dfrac{3}{6}\\).\nYou can check that \\(E(X_i) = \\mu\\) and \\(\\mathrm{Var}(X_i) = \\sigma^2\\), using the fact that \\(\\displaystyle \\sum_{j=1}^m u_j n_j =  \\sum_{i=1}^N x_i\\).\nNow let’s compute \\(\\mathrm{Cov}(X_1, X_2) = E(X_1 X_2) - \\mu^2\\).\n\\[\n\\begin{align*}\nE(X_1 X_2) &= \\sum_{i=1}^m \\sum_{j=1}^m u_i u_j P(X_1 = u_i, X_2 = u_j) \\\\\n    &= \\sum_{i=1}^m \\sum_{j=1}^m u_i u_j P(X_1 = u_i) P(X_2 = u_j \\vert X_1 = u_i) \\\\\n    &= \\sum_{i=1}^m u_i P(X_1 = u_i) \\sum_{j=1}^m u_j P(X_2 = u_j \\vert X_1 = u_i)\\\\\n\\end{align*}\n\\] Now, as we discussed earlier, \\(P(X_1 = u_i) = \\dfrac{n_i}{N}\\). But the second draw from the population, \\(X_2\\) will depend on the first. \\(P(X_2 = u_j \\vert X_1 = u_i) = \\dfrac{n_j}{N-1}\\) if \\(j \\ne i\\) and \\(P(X_2 = u_j \\vert X_1 = u_i) = \\dfrac{n_i-1}{N-1}\\) if \\(j = i\\).\nThus, we can simplify the interior sum to: \\[\n\\begin{align*}\n\\sum_{j=1}^m u_j P(X_2 = u_j \\vert X_1 = u_i) &= \\sum_{\\substack{j=1 \\\\ j \\ne i}}^m u_j \\cdot \\dfrac{n_j}{N-1} + u_i\\cdot \\dfrac{n_i-1}{N-1}\\\\\n  &= \\sum_{\\substack{j=1 \\\\ j \\ne i}}^m u_j \\cdot \\dfrac{n_j}{N-1} + u_i\\cdot \\dfrac{n_i}{N-1} - u_i\\cdot \\dfrac{1}{N-1}\\\\\n  &= \\sum_{j=1}^m  \\dfrac{u_j n_j}{N-1} - \\dfrac{u_i}{N-1}\n\\end{align*}  \n\\] Back to \\(E(X_1 X_2)\\), noting that \\(\\displaystyle \\sum_{i=1}^m u_i n_i = \\sum_{k=1}^N x_k = \\tau = N\\mu\\), that is, the sum total of all the population values, and also note that \\(\\displaystyle \\sum_{i=1}^m u_i^2 n_i = \\sum_{i=1}^N x_i^2 = N(\\sigma^2 + \\mu^2)\\):\n\\[\n\\begin{align*}\nE(X_1 X_2) &= \\sum_{i=1}^m u_i \\dfrac{n_i}{N}\\left[ \\sum_{j=1}^m  \\dfrac{u_j n_j}{N-1} - \\dfrac{u_i}{N-1}\\right]\\\\\n   &= \\dfrac{1}{N(N-1)}\\left[ \\left( \\sum_{i=1}^m u_i n_i\\right)\\left( \\sum_{j=1}^m u_j n_j\\right) - \\sum_{i=1}^m u_i^2 n_i\\right]\\\\\n   &= \\dfrac{1}{N(N-1)} \\left[ \\left(N\\mu\\right)^2 -\\sum_{i=1}^m u_i^2 n_i\\right]\\\\\n   &= \\dfrac{1}{N(N-1)}\\left(N^2 \\mu^2 - N(\\sigma^2 + \\mu^2) \\right)\\\\\n   &= \\mu^2 -\\dfrac{\\sigma^2}{N-1}\n\\end{align*}\n\\] This implies that: \\[\n\\begin{align*}\n\\mathrm{Cov}(X_1, X_2) &= E(X_1X_2) - \\mu^2\\\\\n   &= \\mu^2 -\\dfrac{\\sigma^2}{N-1} - \\mu^2\\\\\n   &= -\\dfrac{\\sigma^2}{N-1}\n\\end{align*}\n\\]\nNow we can put it all together: \\[\n\\begin{align*}\n\\mathrm{Var}(\\overline{X}) &= \\dfrac{1}{n^2} \\left( n\\sigma^2 + n(n-1) \\mathrm{Cov}(X_1, X_2) \\right)\\\\\n   &= \\dfrac{1}{n^2} \\left( n\\sigma^2 - n(n-1)\\dfrac{\\sigma^2}{N-1}\\right)\\\\\n   &= \\dfrac{\\sigma^2}{n}\\left(1- \\dfrac{n-1}{N-1}\\right)\\\\\n   &= \\dfrac{\\sigma^2}{n}\\left(\\dfrac{N-n}{N-1}\\right)\n\\end{align*}\n\\]\n\n\n\nThe quantity \\(\\displaystyle \\left( \\dfrac{N-n}{N-1}\\right)=\\left(1- \\dfrac{n-1}{N-1}\\right)\\) is called the finite population correction. Note that \\(\\displaystyle \\dfrac{n-1}{N-1} \\approx \\dfrac{n}{N}\\), which is called the sampling fraction. The larger the sampling fraction, the larger the sample relative to the population, which means we have more information about the population. This should reduce the variability. The extreme case is when \\(n=N\\), and the sample mean has no variability. In practice, the sampling fraction is very small, and so the finite population correction is approximately 1. This means that the precision of the estimator (determined by the variance) depends only on the sample size, and not on the population size.\n\n\n\n\nWe know that the population variance \\(\\sigma^2\\) is defined by: \\[\n\\sigma^2 = \\dfrac{1}{N}\\sum_{i=1}^N x_i^2 - \\mu^2.\n\\] We can define the quantity \\(\\hat{\\sigma}^2\\), which is a function of the sample \\(X_1, X_2, \\ldots, X_n\\): \\[\n\\begin{align*}\n\\hat{\\sigma}^2 &= \\dfrac{1}{n} \\sum_{i=1}^n (X_i -\\overline{X})^2 \\\\\n    &= \\dfrac{1}{n} \\sum_{i=1}^n X_i^2 -\\overline{X}^2 \\\\\n\\end{align*}\n\\] and use this to estimate \\(\\sigma^2\\). The question is then if this estimator is unbiased. Is \\(E(\\hat{\\sigma}^2) = \\sigma^2\\)?\n\\[\n\\begin{align*}\nE(\\hat{\\sigma}^2) &= E\\left( \\dfrac{1}{n} \\sum_{i=1}^n X_i^2 -\\overline{X}^2 \\right) \\\\\n   &= \\dfrac{1}{n} \\sum_{i=1}^n E\\left(X_i^2\\right) - E\\big(\\overline{X}^2 \\big)\\\\\n   &=  (\\sigma^2 + \\mu^2) - E\\big(\\overline{X}^2 \\big)\\\\\n\\end{align*}\n\\] The last line is because \\(\\mathrm{Var}(X_i) = \\sigma^2 = E(X_i^2) - \\mu^2\\). Doing a similar computation with \\(E\\big(\\overline{X}^2 \\big)\\), we see that (for a simple random sample): \\[\nE\\big(\\overline{X}^2 \\big) = \\mathrm{Var}(\\overline{X}) + \\mu^2 = \\dfrac{\\sigma^2}{n}\\left(\\dfrac{N-n}{N-1} \\right) + \\mu^2.\n\\] Putting these together, and doing some tedious algebra offline, we have \\[\n\\begin{align*}\nE(\\hat{\\sigma}^2) &= (\\sigma^2 + \\mu^2) - \\left[\\frac{\\sigma^2}{n}\\left(\\dfrac{N-n}{N-1} \\right) + \\mu^2\\right] \\\\\n   &= \\dfrac{n\\sigma^2}{n} - \\frac{\\sigma^2}{n}\\left(\\dfrac{N-n}{N-1} \\right) + \\mu^2 - \\mu^2  \\\\\n   &= \\frac{\\sigma^2}{n} \\left[n - \\left(\\dfrac{N-n}{N-1} \\right)\\right] \\\\\n   &= \\sigma^2 \\left[\\left(\\frac{n-1}{n}\\right) \\left(\\dfrac{N}{N-1} \\right)\\right] \\\\\n   &= \\sigma^2 \\left[\\dfrac{nN-N}{nN-n}\\right]\\\\\n\\end{align*}\n\\] This means that \\(E(\\hat{\\sigma}^2) \\ne \\sigma^2\\), and also that \\(\\hat{\\sigma}^2\\) underestimates \\(\\sigma^2\\) on average (since \\(N &gt; n\\)). Therefore, to get an unbiased estimator of the variance of the sample mean, we need to multiply \\(\\hat{\\sigma}^2\\) by the appropriate factor. Note that: \\[\nE\\left[\\left(\\frac{n}{n-1}\\right) \\left(\\dfrac{N-1}{N} \\right)\\hat{\\sigma}^2\\right] = \\sigma^2\n\\] Our goal, of course, is to get an unbiased estimator for the variance of the sample mean. Recall that, for a simple random sample, \\(Var(\\overline{X}) = \\dfrac{\\sigma^2}{n}\\left(\\dfrac{N-n}{N-1}\\right)\\). Let’s substiute the unbiased estimator that we just derived above: \\[\n\\begin{align*}\n\\mathrm{(Estimated)\\, Var}(\\overline{X}) &= \\left(\\frac{n}{n-1}\\right) \\left(\\dfrac{N-1}{N} \\right)\\hat{\\sigma}^2 \\cdot \\frac{1}{n} \\left(\\dfrac{N-n}{N-1}\\right) \\\\\n&= \\frac{\\hat{\\sigma}^2}{n-1}\\left(\\frac{N-n}{N}\\right)\\\\\n&= \\frac{s^2}{n}\\left(1-\\frac{n}{N}\\right)\n\\end{align*}\n\\] where \\(\\displaystyle s^2 = \\dfrac{1}{n-1} \\sum_{i=1}^n \\big(X_i - \\overline{X}\\big)^2\\), so that \\(\\displaystyle \\dfrac{s^2}{n} = \\dfrac{\\hat{\\sigma}^2}{n-1}\\).\nThus we have that \\(s_{\\overline{X}}^2\\) is an unbiased estimator of \\(\\sigma_{\\overline{X}}^2=\\mathrm{Var}(\\overline{X})\\).\nIf the population is dichotomous, then the estimator becomes: \\[\n\\mathrm{Var}(\\hat{p}) = s_{\\hat{p}}^2 = \\frac{s^2}{n} = \\frac{\\hat{p}(1-\\hat{p})}{n-1}.\n\\]\nPutting all this together gives us the table on page 214 of the text, reproduced here:\n\n\n\n\n\n\n\n\n\n\n\n\nPopulation Parameter\nEstimator\nVariance of Estimator (Square of Standard Error)\nEstimated Variance of the Estimator  (Square of Estimated SE)\n\n\n\n\n\\(\\mu\\)\n\\(\\overline{X}\\)\n\\(\\sigma_{\\overline{X}}^2 = \\displaystyle \\dfrac{\\sigma^2}{n}\\left(\\dfrac{N-n}{N-1}\\right)\\)\n\\(s_{\\overline{X}}^2  = \\displaystyle \\dfrac{s^2}{n}\\left(1-\\dfrac{n}{N}\\right)\\)\n\n\n\\(p\\)\n\\(\\hat{p}\\)\n\\(\\sigma_{\\hat{p}}^2 = \\displaystyle \\dfrac{p(1-p)}{n}\\left(\\dfrac{N-n}{N-1}\\right)\\)\n\\(s_{\\hat{p}}^2  = \\displaystyle \\dfrac{\\hat{p}(1-\\hat{p})}{n-1}\\left(1-\\dfrac{n}{N}\\right)\\)\n\n\n\\(\\tau\\)\n\\(T = N\\overline{X}\\)\n\\(\\sigma_{\\tau}^2 = N^2\\sigma_{\\overline{X}}^2\\)\n\\(s_{\\tau}^2 = N^2s_{\\overline{X}}^2\\)\n\n\n\\(\\sigma^2\\)\n\\(\\left(1-\\dfrac{1}{N}\\right)s^2\\)\n\n\n\n\n\n\n\n(Rice 2006; Wasserman 2004; Pimentel 2024; Lohr 2010)",
    "crumbs": [
      "Lecture 3: Survey Sampling, Inference"
    ]
  },
  {
    "objectID": "lectures/lecture-3.html#inference-in-sampling",
    "href": "lectures/lecture-3.html#inference-in-sampling",
    "title": "Survey Sampling: Inference",
    "section": "",
    "text": "Inference involves using a sample to compute an estimate of a population parameter, and the population should always be defined in the context in which the results will be applied.\n\nEstimator: The function (or algorithm) that maps sample data to a number.\n\n\nEstimate: The actual observed value after applying the estimator on the sample (observed) data.\n\n\n\n\n\n\nThen of course the question we would have is how good is our estimator and therefore our estimate? We want \\(\\mu\\), and we have the estimate \\(\\hat{\\mu}\\). How close is this estimate to the true value \\(\\mu\\)? We need a measure of goodness of our estimator. Note that our estimator is random. Each time we take a random sample, we will get a different value of the estimate. We want to know on average, what is the error of our estimator? To compute this, we need to consider the sampling distribution of our estimator. This is just a special name for the probability distribution of the estimator, which is a random variable. The randomness of the estimator is rooted in the randomness of the sampling. The spread of the probability distribution, measured by its standard deviation is one of the determinants of the accuracy of our estimator.\n\n\n\n\n\nIf we would hit our target (the population parameter) on average (that means that the expected value of our estimator is the population parameter), then we only need to consider how much our estimator’s sampling distribution spreads about the mean. The tighter the spread (the smaller the standard deviation), the more accurate the estimator. Now, because we are measuring the error of our estimator, we call the square root of its variance the standard error rather than the standard deviation.\nWhat if, though, the expected value of our estimator is not the target parameter? In this case the difference between the expected value of the estimator and the true value of the population parameter will also contribute to the error. Because of this, we use a measure of goodness of our estimate that incorporates both the spread (standard error) and the average distance from the parameter (we call this bias). This measure is called the Mean Squared Error.\n\n\n\nMean Squared Error: The mean squared error is the expected value of the squared difference between the estimator \\(\\hat{\\theta}\\) and the true value of the population parameter \\(\\theta\\). We denoted it by \\(MSE\\): \\[\nMSE = E\\left[\\left(\\hat{\\theta} - \\theta \\right)^2\\right]\n\\]\n\n\nBias: The bias of an estimator is its distance, on average, from the true value of the population parameter: \\[\n\\operatorname{Bias}(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta\n\\] We call an estimator unbiased if the bias is 0, that is if \\(E(\\hat{\\theta}) = \\theta\\).\n\nExercise Show that \\(MSE =  \\text{Variance} + \\text{Bias}^2\\).\n\n\nSolution\n\n\\[\n\\begin{align*}\n\\mathrm{MSE}(\\hat\\theta)\n&= E\\big[(\\hat\\theta - \\theta)^2\\big] \\\\\n&= E\\big(\\hat\\theta ^2\\big) -2 \\theta E\\big(\\hat\\theta\\big) + \\theta^2\\\\\n&= \\mathrm{Var}\\big(\\hat\\theta\\big) +  \\big[E\\big(\\hat\\theta\\big)\\big]^2 -2 \\theta E\\big(\\hat\\theta\\big) + \\theta^2\\\\\n&= \\mathrm{Var}\\big(\\hat\\theta\\big) + \\big[E\\big(\\hat\\theta\\big) - \\theta\\big]^2\\\\\n&= \\mathrm{Var}(\\hat\\theta) + \\big[\\mathrm{Bias}(\\hat\\theta)\\big]^2.\n\\end{align*}\n\\]\n\nHere is a figure from Lohr’s text that shows the difference between low bias, low variance, and low MSE:\n\n\n\nUnbiased archers, precise archers, and accurate archers\n\n\nThis diagram shows that an estimator \\(\\hat{\\theta}\\) is unbiased if \\(E\\big(\\hat{\\theta}\\big) = \\theta\\), it is precise if \\(\\mathrm{Var}(\\hat{\\theta})\\) is small, but for the estimator to be accurate, both these quantities must be small, and therefore the Mean Squared Error (the sum of the squared bias and the variance) must be small, where \\(MSE = E\\big[\\big(\\hat{\\theta} - \\theta\\big)^2\\big]\\).\n\n\n\nRecall that if we let \\(X_1, X_2, \\ldots, X_n\\) are independent and identically distributed random variables (IID), with common expected value \\(\\mu\\) and variance \\(\\sigma^2\\); and \\(\\overline{X}\\) is the sample mean of this sample \\(\\big(\\displaystyle \\overline{X} = \\dfrac{1}{n} \\sum_{i=1}^n X_i\\big)\\), then \\(E(\\overline{X}) = \\mu\\) and \\(\\mathrm{Var}(\\overline{X}) = \\sigma^2/n\\). (Note: You should be able to show this.)\nNow suppose we have a finite population of size \\(N\\), and we take a simple random sample of size \\(n\\) from this population: \\(X_1, X_2, \\ldots, X_n\\). Now the \\(X_i\\) cannot be IID as we are sampling without replacement. It is easily shown (Theorem A on page 206) that the expected value of the sample mean is still \\(\\mu\\), where \\(\\mu\\) is the population mean. What about \\(\\mathrm{Var}(\\overline{X})\\)?\nIt turns out that ( Theorem B on page 208): \\[\n\\mathrm{Var}(\\overline{X}) = \\dfrac{\\sigma^2}{n}\\left( \\dfrac{N-n}{N-1}\\right).\n\\]\n\n\nClick for the proof\n\n\\[\n\\begin{align*}\n\\mathrm{Var}(\\overline{X}) &= \\mathrm{Var}\\left(\\dfrac{1}{n}\\sum_{i = 1}^n X_i\\right)\\\\\n  &= \\dfrac{1}{n^2} \\mathrm{Var}\\left(\\sum_{i = 1}^n X_i\\right), \\: \\text{because }\\mathrm{Var}(aX) = a^2\\mathrm{Var}(X)\\\\\n  &= \\dfrac{1}{n^2}\\mathrm{Cov}\\left(\\sum_{i = 1}^n X_i,\\sum_{j = 1}^n X_j \\right), \\: \\text{because } \\mathrm{Var}(X) = \\mathrm{Cov}(X,X)\\\\\n  &= \\dfrac{1}{n^2}\\left(\\sum_{i = 1}^n \\mathrm{Var}(X_i) + \\sum_{i = 1}^n \\sum_{\\substack{j=1 \\\\ j \\ne i}}^n \\mathrm{Cov}(X_i,X_j)\\right) \\\\\n  &= \\dfrac{1}{n^2} \\left( n\\sigma^2 + n(n-1) \\mathrm{Cov}(X_1, X_2) \\right), \\: \\text{since all } n(n-1) \\text{ pairs will have the same covariance.}\n\\end{align*}\n\\] This computation implies that if we figure out \\(\\mathrm{Cov}(X_1, X_2)\\), we will able to figure out the variance we need. So let’s compute this covariance. Recall that \\(\\mathrm{Cov}(X_1, X_2) = E(X_1 X_2) - E(X_1)E(X_2)\\).\nWe know that the possible values of the \\(X_i\\) are the population values: \\(x_1, x_2, \\ldots, x_N\\). But some of these could be repeated, which can mess up the probability computations. To simplify our computations, we will define new values \\(u_1, u_2, \\ldots, u_m\\) to be the distinct values in the population, \\(m\\) the number of distinct values, and let \\(n_i\\) be the number of times we see the value \\(u_i\\).\nFor example, suppose \\(N = 6\\) and the population values are \\(1, 1, 4, 4, 4, 7\\). Then \\(x_1 = 1 = x_2, x_3 = x_4 = x_5 = 4\\), and \\(x_6 = 7\\). Using the \\(u_i's\\), we have \\(u_1 = 1, u_2 = 4, u_3 = 7\\), and \\(m=3\\). Further, \\(n_1 = 2, n_2 = 3, n_3 = 1\\).\nNow, if \\(X_i\\) is the \\(i\\)th sample value drawn, then \\(X_i\\) is a discrete random variable such that \\(P(X_i = u_i) = \\dfrac{n_i}{N}\\). This is because there are still \\(N\\) total units in the population, and we have just grouped them by value.\nFor example, using the numbers above, \\(P(X_i = 4) = \\dfrac{3}{6}\\).\nYou can check that \\(E(X_i) = \\mu\\) and \\(\\mathrm{Var}(X_i) = \\sigma^2\\), using the fact that \\(\\displaystyle \\sum_{j=1}^m u_j n_j =  \\sum_{i=1}^N x_i\\).\nNow let’s compute \\(\\mathrm{Cov}(X_1, X_2) = E(X_1 X_2) - \\mu^2\\).\n\\[\n\\begin{align*}\nE(X_1 X_2) &= \\sum_{i=1}^m \\sum_{j=1}^m u_i u_j P(X_1 = u_i, X_2 = u_j) \\\\\n    &= \\sum_{i=1}^m \\sum_{j=1}^m u_i u_j P(X_1 = u_i) P(X_2 = u_j \\vert X_1 = u_i) \\\\\n    &= \\sum_{i=1}^m u_i P(X_1 = u_i) \\sum_{j=1}^m u_j P(X_2 = u_j \\vert X_1 = u_i)\\\\\n\\end{align*}\n\\] Now, as we discussed earlier, \\(P(X_1 = u_i) = \\dfrac{n_i}{N}\\). But the second draw from the population, \\(X_2\\) will depend on the first. \\(P(X_2 = u_j \\vert X_1 = u_i) = \\dfrac{n_j}{N-1}\\) if \\(j \\ne i\\) and \\(P(X_2 = u_j \\vert X_1 = u_i) = \\dfrac{n_i-1}{N-1}\\) if \\(j = i\\).\nThus, we can simplify the interior sum to: \\[\n\\begin{align*}\n\\sum_{j=1}^m u_j P(X_2 = u_j \\vert X_1 = u_i) &= \\sum_{\\substack{j=1 \\\\ j \\ne i}}^m u_j \\cdot \\dfrac{n_j}{N-1} + u_i\\cdot \\dfrac{n_i-1}{N-1}\\\\\n  &= \\sum_{\\substack{j=1 \\\\ j \\ne i}}^m u_j \\cdot \\dfrac{n_j}{N-1} + u_i\\cdot \\dfrac{n_i}{N-1} - u_i\\cdot \\dfrac{1}{N-1}\\\\\n  &= \\sum_{j=1}^m  \\dfrac{u_j n_j}{N-1} - \\dfrac{u_i}{N-1}\n\\end{align*}  \n\\] Back to \\(E(X_1 X_2)\\), noting that \\(\\displaystyle \\sum_{i=1}^m u_i n_i = \\sum_{k=1}^N x_k = \\tau = N\\mu\\), that is, the sum total of all the population values, and also note that \\(\\displaystyle \\sum_{i=1}^m u_i^2 n_i = \\sum_{i=1}^N x_i^2 = N(\\sigma^2 + \\mu^2)\\):\n\\[\n\\begin{align*}\nE(X_1 X_2) &= \\sum_{i=1}^m u_i \\dfrac{n_i}{N}\\left[ \\sum_{j=1}^m  \\dfrac{u_j n_j}{N-1} - \\dfrac{u_i}{N-1}\\right]\\\\\n   &= \\dfrac{1}{N(N-1)}\\left[ \\left( \\sum_{i=1}^m u_i n_i\\right)\\left( \\sum_{j=1}^m u_j n_j\\right) - \\sum_{i=1}^m u_i^2 n_i\\right]\\\\\n   &= \\dfrac{1}{N(N-1)} \\left[ \\left(N\\mu\\right)^2 -\\sum_{i=1}^m u_i^2 n_i\\right]\\\\\n   &= \\dfrac{1}{N(N-1)}\\left(N^2 \\mu^2 - N(\\sigma^2 + \\mu^2) \\right)\\\\\n   &= \\mu^2 -\\dfrac{\\sigma^2}{N-1}\n\\end{align*}\n\\] This implies that: \\[\n\\begin{align*}\n\\mathrm{Cov}(X_1, X_2) &= E(X_1X_2) - \\mu^2\\\\\n   &= \\mu^2 -\\dfrac{\\sigma^2}{N-1} - \\mu^2\\\\\n   &= -\\dfrac{\\sigma^2}{N-1}\n\\end{align*}\n\\]\nNow we can put it all together: \\[\n\\begin{align*}\n\\mathrm{Var}(\\overline{X}) &= \\dfrac{1}{n^2} \\left( n\\sigma^2 + n(n-1) \\mathrm{Cov}(X_1, X_2) \\right)\\\\\n   &= \\dfrac{1}{n^2} \\left( n\\sigma^2 - n(n-1)\\dfrac{\\sigma^2}{N-1}\\right)\\\\\n   &= \\dfrac{\\sigma^2}{n}\\left(1- \\dfrac{n-1}{N-1}\\right)\\\\\n   &= \\dfrac{\\sigma^2}{n}\\left(\\dfrac{N-n}{N-1}\\right)\n\\end{align*}\n\\]\n\n\n\nThe quantity \\(\\displaystyle \\left( \\dfrac{N-n}{N-1}\\right)=\\left(1- \\dfrac{n-1}{N-1}\\right)\\) is called the finite population correction. Note that \\(\\displaystyle \\dfrac{n-1}{N-1} \\approx \\dfrac{n}{N}\\), which is called the sampling fraction. The larger the sampling fraction, the larger the sample relative to the population, which means we have more information about the population. This should reduce the variability. The extreme case is when \\(n=N\\), and the sample mean has no variability. In practice, the sampling fraction is very small, and so the finite population correction is approximately 1. This means that the precision of the estimator (determined by the variance) depends only on the sample size, and not on the population size.\n\n\n\n\nWe know that the population variance \\(\\sigma^2\\) is defined by: \\[\n\\sigma^2 = \\dfrac{1}{N}\\sum_{i=1}^N x_i^2 - \\mu^2.\n\\] We can define the quantity \\(\\hat{\\sigma}^2\\), which is a function of the sample \\(X_1, X_2, \\ldots, X_n\\): \\[\n\\begin{align*}\n\\hat{\\sigma}^2 &= \\dfrac{1}{n} \\sum_{i=1}^n (X_i -\\overline{X})^2 \\\\\n    &= \\dfrac{1}{n} \\sum_{i=1}^n X_i^2 -\\overline{X}^2 \\\\\n\\end{align*}\n\\] and use this to estimate \\(\\sigma^2\\). The question is then if this estimator is unbiased. Is \\(E(\\hat{\\sigma}^2) = \\sigma^2\\)?\n\\[\n\\begin{align*}\nE(\\hat{\\sigma}^2) &= E\\left( \\dfrac{1}{n} \\sum_{i=1}^n X_i^2 -\\overline{X}^2 \\right) \\\\\n   &= \\dfrac{1}{n} \\sum_{i=1}^n E\\left(X_i^2\\right) - E\\big(\\overline{X}^2 \\big)\\\\\n   &=  (\\sigma^2 + \\mu^2) - E\\big(\\overline{X}^2 \\big)\\\\\n\\end{align*}\n\\] The last line is because \\(\\mathrm{Var}(X_i) = \\sigma^2 = E(X_i^2) - \\mu^2\\). Doing a similar computation with \\(E\\big(\\overline{X}^2 \\big)\\), we see that (for a simple random sample): \\[\nE\\big(\\overline{X}^2 \\big) = \\mathrm{Var}(\\overline{X}) + \\mu^2 = \\dfrac{\\sigma^2}{n}\\left(\\dfrac{N-n}{N-1} \\right) + \\mu^2.\n\\] Putting these together, and doing some tedious algebra offline, we have \\[\n\\begin{align*}\nE(\\hat{\\sigma}^2) &= (\\sigma^2 + \\mu^2) - \\left[\\frac{\\sigma^2}{n}\\left(\\dfrac{N-n}{N-1} \\right) + \\mu^2\\right] \\\\\n   &= \\dfrac{n\\sigma^2}{n} - \\frac{\\sigma^2}{n}\\left(\\dfrac{N-n}{N-1} \\right) + \\mu^2 - \\mu^2  \\\\\n   &= \\frac{\\sigma^2}{n} \\left[n - \\left(\\dfrac{N-n}{N-1} \\right)\\right] \\\\\n   &= \\sigma^2 \\left[\\left(\\frac{n-1}{n}\\right) \\left(\\dfrac{N}{N-1} \\right)\\right] \\\\\n   &= \\sigma^2 \\left[\\dfrac{nN-N}{nN-n}\\right]\\\\\n\\end{align*}\n\\] This means that \\(E(\\hat{\\sigma}^2) \\ne \\sigma^2\\), and also that \\(\\hat{\\sigma}^2\\) underestimates \\(\\sigma^2\\) on average (since \\(N &gt; n\\)). Therefore, to get an unbiased estimator of the variance of the sample mean, we need to multiply \\(\\hat{\\sigma}^2\\) by the appropriate factor. Note that: \\[\nE\\left[\\left(\\frac{n}{n-1}\\right) \\left(\\dfrac{N-1}{N} \\right)\\hat{\\sigma}^2\\right] = \\sigma^2\n\\] Our goal, of course, is to get an unbiased estimator for the variance of the sample mean. Recall that, for a simple random sample, \\(Var(\\overline{X}) = \\dfrac{\\sigma^2}{n}\\left(\\dfrac{N-n}{N-1}\\right)\\). Let’s substiute the unbiased estimator that we just derived above: \\[\n\\begin{align*}\n\\mathrm{(Estimated)\\, Var}(\\overline{X}) &= \\left(\\frac{n}{n-1}\\right) \\left(\\dfrac{N-1}{N} \\right)\\hat{\\sigma}^2 \\cdot \\frac{1}{n} \\left(\\dfrac{N-n}{N-1}\\right) \\\\\n&= \\frac{\\hat{\\sigma}^2}{n-1}\\left(\\frac{N-n}{N}\\right)\\\\\n&= \\frac{s^2}{n}\\left(1-\\frac{n}{N}\\right)\n\\end{align*}\n\\] where \\(\\displaystyle s^2 = \\dfrac{1}{n-1} \\sum_{i=1}^n \\big(X_i - \\overline{X}\\big)^2\\), so that \\(\\displaystyle \\dfrac{s^2}{n} = \\dfrac{\\hat{\\sigma}^2}{n-1}\\).\nThus we have that \\(s_{\\overline{X}}^2\\) is an unbiased estimator of \\(\\sigma_{\\overline{X}}^2=\\mathrm{Var}(\\overline{X})\\).\nIf the population is dichotomous, then the estimator becomes: \\[\n\\mathrm{Var}(\\hat{p}) = s_{\\hat{p}}^2 = \\frac{s^2}{n} = \\frac{\\hat{p}(1-\\hat{p})}{n-1}.\n\\]\nPutting all this together gives us the table on page 214 of the text, reproduced here:\n\n\n\n\n\n\n\n\n\n\n\n\nPopulation Parameter\nEstimator\nVariance of Estimator (Square of Standard Error)\nEstimated Variance of the Estimator  (Square of Estimated SE)\n\n\n\n\n\\(\\mu\\)\n\\(\\overline{X}\\)\n\\(\\sigma_{\\overline{X}}^2 = \\displaystyle \\dfrac{\\sigma^2}{n}\\left(\\dfrac{N-n}{N-1}\\right)\\)\n\\(s_{\\overline{X}}^2  = \\displaystyle \\dfrac{s^2}{n}\\left(1-\\dfrac{n}{N}\\right)\\)\n\n\n\\(p\\)\n\\(\\hat{p}\\)\n\\(\\sigma_{\\hat{p}}^2 = \\displaystyle \\dfrac{p(1-p)}{n}\\left(\\dfrac{N-n}{N-1}\\right)\\)\n\\(s_{\\hat{p}}^2  = \\displaystyle \\dfrac{\\hat{p}(1-\\hat{p})}{n-1}\\left(1-\\dfrac{n}{N}\\right)\\)\n\n\n\\(\\tau\\)\n\\(T = N\\overline{X}\\)\n\\(\\sigma_{\\tau}^2 = N^2\\sigma_{\\overline{X}}^2\\)\n\\(s_{\\tau}^2 = N^2s_{\\overline{X}}^2\\)\n\n\n\\(\\sigma^2\\)\n\\(\\left(1-\\dfrac{1}{N}\\right)s^2\\)\n\n\n\n\n\n\n\n(Rice 2006; Wasserman 2004; Pimentel 2024; Lohr 2010)",
    "crumbs": [
      "Lecture 3: Survey Sampling, Inference"
    ]
  },
  {
    "objectID": "lectures/lecture-3.html#references",
    "href": "lectures/lecture-3.html#references",
    "title": "Survey Sampling: Inference",
    "section": "References",
    "text": "References\n\n\nLohr, Sharon L. 2010. Sampling: Design and Analysis. 2nd ed. Cengage.\n\n\nPimentel, Sam. 2024. “STAT 135 Lecture Slides.” Lecture slides (shared privately).\n\n\nRice, John A. 2006. Mathematical Statistics and Data Analysis. 3rd ed. Duxbury Press.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. New York: Springer.",
    "crumbs": [
      "Lecture 3: Survey Sampling, Inference"
    ]
  },
  {
    "objectID": "lectures/lecture-4.html",
    "href": "lectures/lecture-4.html",
    "title": "Survey Sampling: Confidence Intervals",
    "section": "",
    "text": "The CLT states that for large \\(n\\), the sample mean, suitably standardized, will have a CDF that approaches the CDF of the standard Normal. That is, the standardized sample mean converges in distribution to the standard Normal.\nIf \\(X_1, X_2, \\ldots, X_n\\) is an independent and identically distributed sample from a population with mean \\(\\mu\\) and variance \\(\\sigma^2\\), then:\n\\[\n\\left(\\frac{\\overline{X}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\right) = \\sqrt{n}\\left(\\frac{\\overline{X}-\\mu}{\\sigma}\\right) \\overset{dsn}{\\longrightarrow}\\mathcal{N}(0,1)  \\text{ as } n\\longrightarrow \\infty\n\\] The CDF converges to \\(\\Phi\\), which means that: \\[\nP\\left(\\frac{\\overline{X}-\\mu}{\\dfrac{\\sigma}{\\sqrt{n}}} \\le z \\right) = F_{\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt{n}}}(z)\\longrightarrow \\Phi(z)\n\\]\nThe CLT is an incredibly important theorem, because it guarantees that for a large enough sample, no matter what the distribution of the random variables \\(X_i\\), the sample mean behaves as though it is from an approximately \\(\\mathcal{N}(\\mu, \\dfrac{\\sigma^2}{n})\\) distribution.\nNote that the CLT is a limit theorem, so it fully characterizes the asymptotic distribution of the sample mean. It provides a good approximation for large enough samples, so we can compute probabilities such as the \\(P\\)-value, and construct confidence intervals. We usually have a fixed population size \\(N\\), so it doesn’t make sense for the sample size \\(n \\rightarrow \\infty\\), but as long as \\(n\\) is large, but the sampling fraction \\(\\dfrac{n}{N}\\) is small, the normal approximation is pretty good, and how we use it is demonstrated in the following example.\n\n\nThis is an example from the text that is used to illustrate many of the ideas from this chapter. Herkson (JASA 1976) presented data on the number of patients discharged from each of a population of \\(N=393\\) hospitals during January 1986. The mean number of discharges across the population is about 815, and the population standard deviation is about 590.\n\nIf a random sample of \\(n=100\\) is taken from this population with replacement, what is the standard error of the associated estimator of the population mean \\(\\overline{X}\\)?\nWhat is the standard error of \\(\\overline{X}\\) if instead we take a simple random sample of size \\(n=100\\)?\nIf we are sampling with replacement, what is the (approximate) probability that our sample average exceeds 850?\n\n\n\nCheck your answer\n\n\nSince we are sampling with replacement, the random variables form an IID sample, and so the standard error of the sample mean is \\(\\dfrac{\\sigma}{\\sqrt{n}} = \\dfrac{590}{\\sqrt{100}} = 59\\).\nIn the case of an SRS, the standard error of the sample mean is given by \\(\\dfrac{\\sigma}{\\sqrt{n}}\\left(\\dfrac{N-n}{N-1}\\right) = \\dfrac{590}{\\sqrt{100}}\\sqrt{\\left(\\dfrac{393-100}{393-1}\\right)} \\approx 51\\).\nWe want to approximate \\(P(\\overline{X} &gt; 850)\\). By the CLT, \\[\nP(\\overline{X} &gt; 850) = P\\left(\\dfrac{\\overline{X}-815}{59} &gt; \\dfrac{850-815}{59}\\right) = 1-\\Phi\\left(\\dfrac{850-815}{59}\\right) \\approx 0.2765.\n\\] We used 1-pnorm((850-815)/59) to compute the answer.\n\n\n\n\n\n\nAnother way we could use the central limit theorem with estimated standard error is to build a range of plausible values for the population mean from the sample. This range is called the confidence interval. A confidence interval  for some population parameter \\(\\theta\\) is a random interval, whose endpoints are constructed using the sample, such that the interval contains \\(\\theta\\) with some specified probability.\nIt is very important to note the assumption that the population parameter is fixed, and it is the interval that is random, and so the probability of coverage is associated with the random interval.\nSince we compute the endpoints using the random sample, the endpoints are random variables. This means that each time we take a sample of size \\(n\\), and then plug in our observed data, we will get a different realization of this random interval. But because we can use the CLT to approximate probabilities, we can construct intervals that have a probability of \\(1-\\alpha\\) of containing the true value. For example if \\(\\alpha = 0.05\\), we construct an interval that contains the true mean 95% of the times (on average).\nFor \\(0 \\le \\alpha \\le 1\\), let \\(z(\\alpha)\\) denote that value on the \\(x\\)-axis such that the area under the standard normal density curve to the right of \\(z(\\alpha)\\) is \\(\\alpha\\). When we have a particular confidence interval, it is a realization of a random interval, where the random interval has a certain coverage probability of \\(1-\\alpha\\). We call this coverage probability the confidence level.\n\n\n\n\n\n\n\n\n\nLet’s derive the confidence interval for the population mean \\(\\mu\\). By the central limit theorem, we know that \\(\\overline{X}\\) is approximately normal, that is, \\(\\dfrac{\\overline{X}-\\mu}{\\sigma_{\\overline{X}}} \\approx \\mathcal{N}(0,1)\\).\nIf \\(Z\\) follows the standard Normal distribution, then by the definition of \\(z(\\alpha)\\) above, we see that \\[\nP\\big(-z(\\alpha/2) \\le Z \\le z(\\alpha/2)\\big) = 1-\\alpha.\n\\] Therefore, if \\(\\dfrac{\\overline{X} - \\mu}{\\sigma/\\sqrt{n}}\\) is approximately normal, we have that: \\[\nP\\left(-z(\\alpha/2) \\le \\dfrac{\\overline{X} - \\mu}{\\sigma/\\sqrt{n}} \\le z(\\alpha/2)\\right) \\approx 1-\\alpha.\n\\] Now we multiply by \\(\\sigma/\\sqrt{n}\\), subtract \\(\\overline{X}\\) and multiply by \\(-1\\). This gives us the confidence interval that we need: \\[\nP\\left(\\overline{X} - \\frac{\\sigma}{\\sqrt{n}}z(\\alpha/2) \\le  \\mu \\le \\overline{X} +  \\frac{\\sigma}{\\sqrt{n}}z(\\alpha/2)\\right) \\approx 1-\\alpha.\n\\] This statement says that the chance of this random interval, \\(\\left(\\overline{X} - \\dfrac{\\sigma}{\\sqrt{n}}z(\\alpha/2) ,\\; \\overline{X} +  \\dfrac{\\sigma}{\\sqrt{n}}z(\\alpha/2)\\right)\\) capturing the mean is approximately \\(1-\\alpha\\), and so the interval is called a \\(100(1-\\alpha)%\\) confidence interval.\nWe can then plug in our observed value of \\(\\overline{X}\\) and will get a realization of the random interval: \\(\\left(\\overline{x} - \\dfrac{\\sigma}{\\sqrt{n}}z(\\alpha/2) ,\\; \\overline{x} +  \\dfrac{\\sigma}{\\sqrt{n}}z(\\alpha/2)\\right).\\) Note that this interval is not random. It is just an interval on the real line and as \\(\\mu\\) is just some fixed constant, it either lies in this interval or does not. Therefore, once we plug in the observed sample mean, and the observed value of the estimator \\(s_{\\overline{X}}\\), we don’t have any randomness. All the randomness is in the sampling procedure.\nWe can use the confidence interval to plan our data collection. Since the width of the confidence interval is given by \\(2\\times \\dfrac{\\sigma}{\\sqrt{n}} \\times z(\\alpha)\\), it is determined by \\(\\sigma\\) and by \\(\\sqrt{n}\\). Now \\(\\sigma\\) is a constant of the population, so we can’t do much with it, but we can choose \\(n\\) so that our confidence interval is as narrow as we desire. The margin of error of the confidence interval is given by $ z().$\nExercise (Problem 8 from section 7.7) A sample of size 100 is taken from a population that has a proportion \\(p = 1/5\\).\n\nFind \\(\\delta\\) such that \\(P\\big(\\lvert \\hat{p}-p\\rvert \\ge \\delta\\big)=0.025\\)\nIf, in the sample, \\(\\hat{p} = 0.25\\), will the 95% confidence interval for \\(p\\) contain the true value for \\(p\\)?\n\n\n\nCheck your answer\n\n\n\\(\\delta = 0.0896\\), \\(p\\) is given to be \\(\\dfrac{1}{5}\\). Therefore, \\(\\sigma_{\\hat{p}} = \\displaystyle \\sqrt{\\dfrac{\\frac{1}{5}\\cdot \\frac{4}{5}}{100}} = \\frac{2}{50}.\\)\n\nBy the Central Limit Theorem, \\(\\hat{p}\\) is approximately \\(\\mathcal{N}(p, \\sigma_{\\hat{p}}^2)\\).\n\\[\n\\begin{align*}\nP\\big(\\lvert \\hat{p}-p\\rvert \\ge \\delta\\big) &= 0.025 \\\\\n\\Rightarrow P\\big(\\lvert \\hat{p}-p\\rvert &lt; \\delta\\big) &= 0.975 \\\\\n\\Rightarrow P(-\\delta &lt; \\hat{p}-p &lt; \\delta)  &= 0.975 \\\\\n\\Rightarrow P\\left(-\\frac{\\delta}{\\sigma_{\\hat{p}}} &lt; \\frac{\\hat{p}-p}{\\sigma_{\\hat{p}}} &lt; \\frac{\\delta}{\\sigma_{\\hat{p}}}\\right)  &= 0.975 \\\\\n\\Rightarrow P\\left(-\\frac{\\delta}{\\sigma_{\\hat{p}}} &lt; Z &lt; \\frac{\\delta}{\\sigma_{\\hat{p}}}\\right)  &\\approx 0.975 \\\\\n\\Rightarrow \\Phi\\left(\\frac{\\delta}{\\sigma_{\\hat{p}}}\\right) - \\Phi\\left(-\\frac{\\delta}{\\sigma_{\\hat{p}}}\\right) &\\approx 0.975 \\\\\n\\Rightarrow 2\\Phi\\left(\\frac{\\delta}{\\sigma_{\\hat{p}}}\\right) -1 &\\approx 0.975 \\\\\n\\Rightarrow \\Phi\\left(\\frac{\\delta}{\\sigma_{\\hat{p}}}\\right) &\\approx 0.9875 \\\\\n\\Rightarrow \\frac{\\delta}{\\sigma_{\\hat{p}}} &\\approx 2.24\\\\\n\\end{align*}\n\\] Where we used qnorm(0.9875) to obtain 2.24. Plugging in the value of \\(\\sigma_{\\hat{p}} = \\dfrac{2}{50}\\), we get that \\(\\delta\\) is about \\(0.0896\\).\n\nYes.\n\n\\(z(\\alpha/2) = 1.96\\), and the 95% confidence interval is given by \\(\\hat{p} \\pm 1.96\\times \\dfrac{2}{50}\\). Since \\(\\hat{p} = 0.25\\), this gives us \\(0.25 \\pm 1.96\\times \\dfrac{2}{50} = (0.1716, 0.3284)\\) which contains \\(p = \\dfrac{1}{5}.\\)\n\nExercise 20 different polling companies have conducted independent surveys to estimate the proportion of US voters who approve of RFK Jr’s stewardship of Health and Human Services. Each company estimates this proportion using a 95% confidence interval. About how many do you think will be successful in covering the true proportion?\n\n\nCheck your answer\n\nIf we let \\(Y\\) be the number of confidence intervals out of 20 that are successful, then since each interval has a 0.95 chance of success, we see that \\(Y\\sim Bin(20, 0.95)\\). Therefore the expected number of successful intervals is \\(E(Y) = 20\\times 0.95 = 19.\\)\n\n\n(Rice 2006; Wasserman 2004; Pimentel 2024; Lohr 2010)",
    "crumbs": [
      "Lecture 4: Wrapping up Sampling"
    ]
  },
  {
    "objectID": "lectures/lecture-4.html#the-asymptotic-sampling-distribution-of-the-sample-mean",
    "href": "lectures/lecture-4.html#the-asymptotic-sampling-distribution-of-the-sample-mean",
    "title": "Survey Sampling: Confidence Intervals",
    "section": "",
    "text": "The CLT states that for large \\(n\\), the sample mean, suitably standardized, will have a CDF that approaches the CDF of the standard Normal. That is, the standardized sample mean converges in distribution to the standard Normal.\nIf \\(X_1, X_2, \\ldots, X_n\\) is an independent and identically distributed sample from a population with mean \\(\\mu\\) and variance \\(\\sigma^2\\), then:\n\\[\n\\left(\\frac{\\overline{X}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\right) = \\sqrt{n}\\left(\\frac{\\overline{X}-\\mu}{\\sigma}\\right) \\overset{dsn}{\\longrightarrow}\\mathcal{N}(0,1)  \\text{ as } n\\longrightarrow \\infty\n\\] The CDF converges to \\(\\Phi\\), which means that: \\[\nP\\left(\\frac{\\overline{X}-\\mu}{\\dfrac{\\sigma}{\\sqrt{n}}} \\le z \\right) = F_{\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt{n}}}(z)\\longrightarrow \\Phi(z)\n\\]\nThe CLT is an incredibly important theorem, because it guarantees that for a large enough sample, no matter what the distribution of the random variables \\(X_i\\), the sample mean behaves as though it is from an approximately \\(\\mathcal{N}(\\mu, \\dfrac{\\sigma^2}{n})\\) distribution.\nNote that the CLT is a limit theorem, so it fully characterizes the asymptotic distribution of the sample mean. It provides a good approximation for large enough samples, so we can compute probabilities such as the \\(P\\)-value, and construct confidence intervals. We usually have a fixed population size \\(N\\), so it doesn’t make sense for the sample size \\(n \\rightarrow \\infty\\), but as long as \\(n\\) is large, but the sampling fraction \\(\\dfrac{n}{N}\\) is small, the normal approximation is pretty good, and how we use it is demonstrated in the following example.\n\n\nThis is an example from the text that is used to illustrate many of the ideas from this chapter. Herkson (JASA 1976) presented data on the number of patients discharged from each of a population of \\(N=393\\) hospitals during January 1986. The mean number of discharges across the population is about 815, and the population standard deviation is about 590.\n\nIf a random sample of \\(n=100\\) is taken from this population with replacement, what is the standard error of the associated estimator of the population mean \\(\\overline{X}\\)?\nWhat is the standard error of \\(\\overline{X}\\) if instead we take a simple random sample of size \\(n=100\\)?\nIf we are sampling with replacement, what is the (approximate) probability that our sample average exceeds 850?\n\n\n\nCheck your answer\n\n\nSince we are sampling with replacement, the random variables form an IID sample, and so the standard error of the sample mean is \\(\\dfrac{\\sigma}{\\sqrt{n}} = \\dfrac{590}{\\sqrt{100}} = 59\\).\nIn the case of an SRS, the standard error of the sample mean is given by \\(\\dfrac{\\sigma}{\\sqrt{n}}\\left(\\dfrac{N-n}{N-1}\\right) = \\dfrac{590}{\\sqrt{100}}\\sqrt{\\left(\\dfrac{393-100}{393-1}\\right)} \\approx 51\\).\nWe want to approximate \\(P(\\overline{X} &gt; 850)\\). By the CLT, \\[\nP(\\overline{X} &gt; 850) = P\\left(\\dfrac{\\overline{X}-815}{59} &gt; \\dfrac{850-815}{59}\\right) = 1-\\Phi\\left(\\dfrac{850-815}{59}\\right) \\approx 0.2765.\n\\] We used 1-pnorm((850-815)/59) to compute the answer.\n\n\n\n\n\n\nAnother way we could use the central limit theorem with estimated standard error is to build a range of plausible values for the population mean from the sample. This range is called the confidence interval. A confidence interval  for some population parameter \\(\\theta\\) is a random interval, whose endpoints are constructed using the sample, such that the interval contains \\(\\theta\\) with some specified probability.\nIt is very important to note the assumption that the population parameter is fixed, and it is the interval that is random, and so the probability of coverage is associated with the random interval.\nSince we compute the endpoints using the random sample, the endpoints are random variables. This means that each time we take a sample of size \\(n\\), and then plug in our observed data, we will get a different realization of this random interval. But because we can use the CLT to approximate probabilities, we can construct intervals that have a probability of \\(1-\\alpha\\) of containing the true value. For example if \\(\\alpha = 0.05\\), we construct an interval that contains the true mean 95% of the times (on average).\nFor \\(0 \\le \\alpha \\le 1\\), let \\(z(\\alpha)\\) denote that value on the \\(x\\)-axis such that the area under the standard normal density curve to the right of \\(z(\\alpha)\\) is \\(\\alpha\\). When we have a particular confidence interval, it is a realization of a random interval, where the random interval has a certain coverage probability of \\(1-\\alpha\\). We call this coverage probability the confidence level.\n\n\n\n\n\n\n\n\n\nLet’s derive the confidence interval for the population mean \\(\\mu\\). By the central limit theorem, we know that \\(\\overline{X}\\) is approximately normal, that is, \\(\\dfrac{\\overline{X}-\\mu}{\\sigma_{\\overline{X}}} \\approx \\mathcal{N}(0,1)\\).\nIf \\(Z\\) follows the standard Normal distribution, then by the definition of \\(z(\\alpha)\\) above, we see that \\[\nP\\big(-z(\\alpha/2) \\le Z \\le z(\\alpha/2)\\big) = 1-\\alpha.\n\\] Therefore, if \\(\\dfrac{\\overline{X} - \\mu}{\\sigma/\\sqrt{n}}\\) is approximately normal, we have that: \\[\nP\\left(-z(\\alpha/2) \\le \\dfrac{\\overline{X} - \\mu}{\\sigma/\\sqrt{n}} \\le z(\\alpha/2)\\right) \\approx 1-\\alpha.\n\\] Now we multiply by \\(\\sigma/\\sqrt{n}\\), subtract \\(\\overline{X}\\) and multiply by \\(-1\\). This gives us the confidence interval that we need: \\[\nP\\left(\\overline{X} - \\frac{\\sigma}{\\sqrt{n}}z(\\alpha/2) \\le  \\mu \\le \\overline{X} +  \\frac{\\sigma}{\\sqrt{n}}z(\\alpha/2)\\right) \\approx 1-\\alpha.\n\\] This statement says that the chance of this random interval, \\(\\left(\\overline{X} - \\dfrac{\\sigma}{\\sqrt{n}}z(\\alpha/2) ,\\; \\overline{X} +  \\dfrac{\\sigma}{\\sqrt{n}}z(\\alpha/2)\\right)\\) capturing the mean is approximately \\(1-\\alpha\\), and so the interval is called a \\(100(1-\\alpha)%\\) confidence interval.\nWe can then plug in our observed value of \\(\\overline{X}\\) and will get a realization of the random interval: \\(\\left(\\overline{x} - \\dfrac{\\sigma}{\\sqrt{n}}z(\\alpha/2) ,\\; \\overline{x} +  \\dfrac{\\sigma}{\\sqrt{n}}z(\\alpha/2)\\right).\\) Note that this interval is not random. It is just an interval on the real line and as \\(\\mu\\) is just some fixed constant, it either lies in this interval or does not. Therefore, once we plug in the observed sample mean, and the observed value of the estimator \\(s_{\\overline{X}}\\), we don’t have any randomness. All the randomness is in the sampling procedure.\nWe can use the confidence interval to plan our data collection. Since the width of the confidence interval is given by \\(2\\times \\dfrac{\\sigma}{\\sqrt{n}} \\times z(\\alpha)\\), it is determined by \\(\\sigma\\) and by \\(\\sqrt{n}\\). Now \\(\\sigma\\) is a constant of the population, so we can’t do much with it, but we can choose \\(n\\) so that our confidence interval is as narrow as we desire. The margin of error of the confidence interval is given by $ z().$\nExercise (Problem 8 from section 7.7) A sample of size 100 is taken from a population that has a proportion \\(p = 1/5\\).\n\nFind \\(\\delta\\) such that \\(P\\big(\\lvert \\hat{p}-p\\rvert \\ge \\delta\\big)=0.025\\)\nIf, in the sample, \\(\\hat{p} = 0.25\\), will the 95% confidence interval for \\(p\\) contain the true value for \\(p\\)?\n\n\n\nCheck your answer\n\n\n\\(\\delta = 0.0896\\), \\(p\\) is given to be \\(\\dfrac{1}{5}\\). Therefore, \\(\\sigma_{\\hat{p}} = \\displaystyle \\sqrt{\\dfrac{\\frac{1}{5}\\cdot \\frac{4}{5}}{100}} = \\frac{2}{50}.\\)\n\nBy the Central Limit Theorem, \\(\\hat{p}\\) is approximately \\(\\mathcal{N}(p, \\sigma_{\\hat{p}}^2)\\).\n\\[\n\\begin{align*}\nP\\big(\\lvert \\hat{p}-p\\rvert \\ge \\delta\\big) &= 0.025 \\\\\n\\Rightarrow P\\big(\\lvert \\hat{p}-p\\rvert &lt; \\delta\\big) &= 0.975 \\\\\n\\Rightarrow P(-\\delta &lt; \\hat{p}-p &lt; \\delta)  &= 0.975 \\\\\n\\Rightarrow P\\left(-\\frac{\\delta}{\\sigma_{\\hat{p}}} &lt; \\frac{\\hat{p}-p}{\\sigma_{\\hat{p}}} &lt; \\frac{\\delta}{\\sigma_{\\hat{p}}}\\right)  &= 0.975 \\\\\n\\Rightarrow P\\left(-\\frac{\\delta}{\\sigma_{\\hat{p}}} &lt; Z &lt; \\frac{\\delta}{\\sigma_{\\hat{p}}}\\right)  &\\approx 0.975 \\\\\n\\Rightarrow \\Phi\\left(\\frac{\\delta}{\\sigma_{\\hat{p}}}\\right) - \\Phi\\left(-\\frac{\\delta}{\\sigma_{\\hat{p}}}\\right) &\\approx 0.975 \\\\\n\\Rightarrow 2\\Phi\\left(\\frac{\\delta}{\\sigma_{\\hat{p}}}\\right) -1 &\\approx 0.975 \\\\\n\\Rightarrow \\Phi\\left(\\frac{\\delta}{\\sigma_{\\hat{p}}}\\right) &\\approx 0.9875 \\\\\n\\Rightarrow \\frac{\\delta}{\\sigma_{\\hat{p}}} &\\approx 2.24\\\\\n\\end{align*}\n\\] Where we used qnorm(0.9875) to obtain 2.24. Plugging in the value of \\(\\sigma_{\\hat{p}} = \\dfrac{2}{50}\\), we get that \\(\\delta\\) is about \\(0.0896\\).\n\nYes.\n\n\\(z(\\alpha/2) = 1.96\\), and the 95% confidence interval is given by \\(\\hat{p} \\pm 1.96\\times \\dfrac{2}{50}\\). Since \\(\\hat{p} = 0.25\\), this gives us \\(0.25 \\pm 1.96\\times \\dfrac{2}{50} = (0.1716, 0.3284)\\) which contains \\(p = \\dfrac{1}{5}.\\)\n\nExercise 20 different polling companies have conducted independent surveys to estimate the proportion of US voters who approve of RFK Jr’s stewardship of Health and Human Services. Each company estimates this proportion using a 95% confidence interval. About how many do you think will be successful in covering the true proportion?\n\n\nCheck your answer\n\nIf we let \\(Y\\) be the number of confidence intervals out of 20 that are successful, then since each interval has a 0.95 chance of success, we see that \\(Y\\sim Bin(20, 0.95)\\). Therefore the expected number of successful intervals is \\(E(Y) = 20\\times 0.95 = 19.\\)\n\n\n(Rice 2006; Wasserman 2004; Pimentel 2024; Lohr 2010)",
    "crumbs": [
      "Lecture 4: Wrapping up Sampling"
    ]
  },
  {
    "objectID": "lectures/lecture-4.html#references",
    "href": "lectures/lecture-4.html#references",
    "title": "Survey Sampling: Confidence Intervals",
    "section": "References",
    "text": "References\n\n\nLohr, Sharon L. 2010. Sampling: Design and Analysis. 2nd ed. Cengage.\n\n\nPimentel, Sam. 2024. “STAT 135 Lecture Slides.” Lecture slides (shared privately).\n\n\nRice, John A. 2006. Mathematical Statistics and Data Analysis. 3rd ed. Duxbury Press.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. New York: Springer.",
    "crumbs": [
      "Lecture 4: Wrapping up Sampling"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stat 135: Concepts of Statistics",
    "section": "",
    "text": "Ed\n\n  DataHub\n\n  Gradescope\n\n  bCourses\n\n\nNo matching items",
    "crumbs": [
      "Home / Schedule"
    ]
  },
  {
    "objectID": "index.html#welcome-to-stat-135",
    "href": "index.html#welcome-to-stat-135",
    "title": "Stat 135: Concepts of Statistics",
    "section": "Welcome to Stat 135!",
    "text": "Welcome to Stat 135!\n\n\n\n\n\n\nIMPORTANT\n\n\n\nIf you need to be manually added to bcourses, please reach out to Thomas.",
    "crumbs": [
      "Home / Schedule"
    ]
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Stat 135: Concepts of Statistics",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n   Week 1\n\n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           \n           \n           \n           Jan 21:\n           \n           \n              Lecture 1 Overview\n           \n           \n                \n                \n                  \n                    Syllabus\n                  \n                  \n                  \n                    Diagnostic Test\n                  \n                  \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           \n           \n           \n           Jan 23:\n           \n           \n              Lecture 2 Introduction to Survey Sampling\n           \n           \n                \n           \n                \n           \n        \n   \n   \n   \n  \n\n   Week 2\n\n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           \n           \n           \n           Jan 26:\n           \n           \n              Lecture 3 Inference in Survey Sampling\n           \n           \n                \n                \n                  \n                    Homework 1\n                  \n                  \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           \n           \n           \n           Jan 27:\n           \n           \n              Lab 1 Lab 1: Review of Probability and R\n           \n           \n                \n                \n                  \n                    Probability Theory Refresher\n                  \n                  \n                  \n                    R Introduction\n                  \n                  \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           \n           \n           \n           Jan 28:\n           \n           \n              Lecture 4 Confidence Intervals for Population Parameters\n           \n           \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           \n           \n           \n           Jan 30:\n           \n           \n              Lecture 5 Method of Moments Estimation\n           \n           \n                \n           \n                \n           \n        \n   \n   \n   \n  \n\n   Week 3\n\n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           \n           \n           \n           Feb 2:\n           \n           \n              Lecture 6 More about Estimators, and Mathematical Digressions\n           \n           \n                \n                \n                  \n                    Homework 2\n                  \n                  \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           \n           \n           \n           Feb 3:\n           \n           \n              Lab 2 Lab 2\n           \n           \n                \n                \n                  \n                    Lab 2 Exercises\n                  \n                  \n                  \n                    Lab 2 Rmd\n                  \n                  \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           \n           \n           \n           Feb 4:\n           \n           \n              Lecture 7 Computing Standard Errors of MoM Estimators\n           \n           \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           \n           \n           \n           Feb 6:\n           \n           \n              Lecture 8 Computing Standard Errors, continued\n           \n           \n                \n           \n                \n           \n        \n   \n   \n   \n  \n\n   Week 4\n\n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           \n           \n           \n           Feb 9:\n           \n           \n              Lecture 9 Maximum Likelihood Estimation\n           \n           \n                \n                \n                  \n                    Homework 3\n                  \n                  \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           \n           \n           \n           Feb 10:\n           \n           \n              Lab 3 Lab 3\n           \n           \n                \n                \n                  \n                    Lab 3 Exercises\n                  \n                  \n                  \n                    Lab 3 Rmd\n                  \n                  \n                  \n                    Homework 3\n                  \n                  \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           \n           \n           \n           Feb 11:\n           \n           \n              Lecture 10 Large Sample Theory for MLE\n           \n           \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           \n           \n           \n           Feb 13:\n           \n           \n              Lecture 11 Confidence Intervals, Introducing the Bayesian Approach.\n           \n           \n                \n           \n                \n           \n        \n   \n   \n   \n  \n\n\nNo matching items",
    "crumbs": [
      "Home / Schedule"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Description",
    "section": "",
    "text": "This is one of the three foundational courses of the Statistics Major, the other two being Stat 134 (Concepts of Probability) and Stat 133 (Concepts of Computing). While Stat 134, which is a serious prerequisite for Stat 135, is a course in probability, Stat 135 is a course in statistical inference. It is a comprehensive survey course in statistical theory and methodology. Topics include parameter estimation, hypothesis testing, statistical tests (parametric and non parametric) and linear regression (single and an example of multiple). We will cover most of the content of chapters 7 through 14 in the text Mathematical Statistics and Data Analysis by John Rice (3rd Edition), with a brief look at the content in chapters 5 and 6.\n\n\nBy the end of the semester, you should be able to:\n\nClearly interpret point estimates, confidence intervals, and hypothesis tests for an audience without statistical training.\nConstruct common estimators, statistical tests and confidence interval procedures using probability theory.\nEvaluate the relative strengths and limitations of several estimation or inference procedures for the same problem using mathematical concepts including unbiasedness, efficiency, and power.\nRecommend an approach and carry out estimation and inference for canonical statistics problems including tests of association between two variables and fitting probability distributions to univariate data.\n\n\n\n\n\nSTAT 134 or an equivalent course in probability theory. Do NOT take 134 and 135 concurrently!!\nMultivariable calculus, especially Lagrange multipliers.\nFamiliarity with moment-generating functions.\nFamiliarity with basic R concepts equivalent to the first ~6 weeks of Stat 133. Note that assignments involving computing must be completed in R.\nFamiliarity with linear algebra (matrix operations, inverses, and eigenvalues) for chapter 14.\n\n\n\n\n\nMathematical Statistics and Data Analysis (3rd Edition), by John Rice: This is the main text that we will follow, and exercises will mostly be from here. Make sure that you have the third edition.\nR for Data Science, by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund\nStatistics, by Freedman, Pisani, and Purves: This is the text for Stat 2. It has no coding, but nevertheless is a wonderful book to read, and I strongly recommend reading through it to improve your understanding of statistics.\nVeridical Data Science, by Bin Yu and Rebecca Barter: This is a new book written by Prof. Yu and R. Barter and introduces a framework to practice data science. Though it doesn’t really talk about statistical inference, which is the focus of our class, it discusses how to apply the methods to get reproducible and trustworthy results.\nStat Labs, by Deborah Nolan and Terry Speed: Statistical topics are introduced via case studies.\n\nAs we progress through the course, I may add more books to this list.",
    "crumbs": [
      "About Stat 135"
    ]
  },
  {
    "objectID": "about.html#about-stat-135-concepts-of-statistics",
    "href": "about.html#about-stat-135-concepts-of-statistics",
    "title": "Description",
    "section": "",
    "text": "This is one of the three foundational courses of the Statistics Major, the other two being Stat 134 (Concepts of Probability) and Stat 133 (Concepts of Computing). While Stat 134, which is a serious prerequisite for Stat 135, is a course in probability, Stat 135 is a course in statistical inference. It is a comprehensive survey course in statistical theory and methodology. Topics include parameter estimation, hypothesis testing, statistical tests (parametric and non parametric) and linear regression (single and an example of multiple). We will cover most of the content of chapters 7 through 14 in the text Mathematical Statistics and Data Analysis by John Rice (3rd Edition), with a brief look at the content in chapters 5 and 6.\n\n\nBy the end of the semester, you should be able to:\n\nClearly interpret point estimates, confidence intervals, and hypothesis tests for an audience without statistical training.\nConstruct common estimators, statistical tests and confidence interval procedures using probability theory.\nEvaluate the relative strengths and limitations of several estimation or inference procedures for the same problem using mathematical concepts including unbiasedness, efficiency, and power.\nRecommend an approach and carry out estimation and inference for canonical statistics problems including tests of association between two variables and fitting probability distributions to univariate data.\n\n\n\n\n\nSTAT 134 or an equivalent course in probability theory. Do NOT take 134 and 135 concurrently!!\nMultivariable calculus, especially Lagrange multipliers.\nFamiliarity with moment-generating functions.\nFamiliarity with basic R concepts equivalent to the first ~6 weeks of Stat 133. Note that assignments involving computing must be completed in R.\nFamiliarity with linear algebra (matrix operations, inverses, and eigenvalues) for chapter 14.\n\n\n\n\n\nMathematical Statistics and Data Analysis (3rd Edition), by John Rice: This is the main text that we will follow, and exercises will mostly be from here. Make sure that you have the third edition.\nR for Data Science, by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund\nStatistics, by Freedman, Pisani, and Purves: This is the text for Stat 2. It has no coding, but nevertheless is a wonderful book to read, and I strongly recommend reading through it to improve your understanding of statistics.\nVeridical Data Science, by Bin Yu and Rebecca Barter: This is a new book written by Prof. Yu and R. Barter and introduces a framework to practice data science. Though it doesn’t really talk about statistical inference, which is the focus of our class, it discusses how to apply the methods to get reproducible and trustworthy results.\nStat Labs, by Deborah Nolan and Terry Speed: Statistical topics are introduced via case studies.\n\nAs we progress through the course, I may add more books to this list.",
    "crumbs": [
      "About Stat 135"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Lectures will meet on MWF from 2 - 3 pm in Evans 10. Your instructor is Shobhana Murali Stoyanov.\nLectures will cover core theory and concepts, with supporting data analysis examples. To get the full benefit of lecture, it is best to read the supporting material ahead of time. When slides or R code are shown in class, they will be posted online after class. However, lectures will not always have associated slides. I will not be posting recordings of the lectures, but if you have to miss class due to an emergency or unavoidable circumstance, the class notes and text should suffice. Please do come and see me so we can review what you have missed.\nLecture attendance will be measured using occasional quizzes. There will be roughly 8-10 of these handed out in lecture throughout the semester. You need to complete five of them to get the full attendance credit.\n\n\n\nThe sections meet once a week, on Tuesdays, for two hours. The individual section times will be listed in the course calendar. Section time will be spent working on practice problems. Since some problems will involve computing you should plan to always bring your laptop. You may attend a lab for which you are not enrolled (physical space permitting). Labs will not be recorded so attendance is strongly recommended.\nYour GSIs are Chuao Dong, Thomas Lee, and Toby Roemer.\n\n\n\nProf. Stoyanov and one of the GSIs will hold individual office hours each week. In addition, there will be group office hours in one of the 3rd floor classrooms in Evans, the room and hours TBA. You can go to these to get questions answered about homework or any concepts discussed in class, or help with your coding assignments.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#logistics",
    "href": "syllabus.html#logistics",
    "title": "Syllabus",
    "section": "",
    "text": "Lectures will meet on MWF from 2 - 3 pm in Evans 10. Your instructor is Shobhana Murali Stoyanov.\nLectures will cover core theory and concepts, with supporting data analysis examples. To get the full benefit of lecture, it is best to read the supporting material ahead of time. When slides or R code are shown in class, they will be posted online after class. However, lectures will not always have associated slides. I will not be posting recordings of the lectures, but if you have to miss class due to an emergency or unavoidable circumstance, the class notes and text should suffice. Please do come and see me so we can review what you have missed.\nLecture attendance will be measured using occasional quizzes. There will be roughly 8-10 of these handed out in lecture throughout the semester. You need to complete five of them to get the full attendance credit.\n\n\n\nThe sections meet once a week, on Tuesdays, for two hours. The individual section times will be listed in the course calendar. Section time will be spent working on practice problems. Since some problems will involve computing you should plan to always bring your laptop. You may attend a lab for which you are not enrolled (physical space permitting). Labs will not be recorded so attendance is strongly recommended.\nYour GSIs are Chuao Dong, Thomas Lee, and Toby Roemer.\n\n\n\nProf. Stoyanov and one of the GSIs will hold individual office hours each week. In addition, there will be group office hours in one of the 3rd floor classrooms in Evans, the room and hours TBA. You can go to these to get questions answered about homework or any concepts discussed in class, or help with your coding assignments.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#stat-scholars-program",
    "href": "syllabus.html#stat-scholars-program",
    "title": "Syllabus",
    "section": "Stat Scholars Program",
    "text": "Stat Scholars Program\nThe new Stat Scholars Program will be available to Stat 135 students to provide community, academic support, and more such as answers to your questions about the stat major, new directions in statistics, research being done in the stat department etc. Applications will be sent out soon, begin checking your mail next week.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#assessments",
    "href": "syllabus.html#assessments",
    "title": "Syllabus",
    "section": "Assessments",
    "text": "Assessments\n\nHomework Assignments\nHomework assignments will be due roughly every week or so during the semester, starting in the second week. Homework will be posted to Gradescope usually by Friday, and will generally be due the following Friday at 11:59 pm. Homework will be a combination of analytical and computational exercises done “by hand” and data analysis using R. If you turn in your homework late, you will get half credit for homework that is up to 24 hours late (if you have not requested an extension), and no credit after that.\n\n\nQuizzes\nThere will be four 50-minute quizzes to test your understanding of homework and lecture. You will take the quizzes in the CBTF (Computer-Based Testing Facility) in 200 Sutardja Dai Hall. The dates of the quizzes are: Feb 12/13, Feb 26/27, Apr 9/10, and Apr 30/May 1. You will have to schedule your quiz during the given dates at the CBTF. We do not schedule your quiz for you. Note that DSP students will also take it in the CBTF and will get their extended time. We will drop your lowest quiz score, and you may retake ** at most one** quiz, also in the CBTF, during the week following the original quiz dates. Dates for each retake will be announced later, and you will have to fill out a form to be registered for the retake.\n\n\nExams\nThere will be one midterm exam and the final exam.\n\nThe midterm exam will be a two hour exam which will be held in the evening from 7-9 pm  on Wednesday, March 11 in VLSB 2050.\nThe final exam time and day are Tuesday, May 12, 11:30 am - 2:30 pm (group 6). If you do not take the final exam, you will not pass the class.\n\n\n\nExtra Credit Opportunities\nExtra credit is assigned at the end of the semester after the grade bins have been determined. Ways to get extra credit (it will be added to your overall course percentage):\n\nDiagnostic test: 0.25% for submission with some clear attempt at solving the questions.\nEdStem: The top 5 student answerers will get up to 0.5% extra credit.\n\n\n\nAttendance Quizzes\nAs stated above, there will be 8-10 attendance quizzes handed out in lecture throughout the semester. These will be graded on completion, and you will need to complete five of them to get all the attendance points.\n\n\nOverall Score\nYour letter grade for the course will be based a weighted average of your assessments, as follows:\n\nHomework (each assignment weighted equally, drop two lowest): 15%\nQuizzes: 15% (equally weighted, drop lowest)\nMidterm: 25% (can be clobbered by the final)\nFinal exam: 40% or 65% (if higher than the midterm)\nAttendance quizzes: 5%\n\nRough grade bins: Students earning a course average of at least 88% are guaranteed to receive an A- or better, students earning a course average of at least 75% are guaranteed a B- or better, and students earning at least 60% on their course average are guaranteed at least a C-. These bins might move down, depending on how the class does.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#important-sites-to-bookmark",
    "href": "syllabus.html#important-sites-to-bookmark",
    "title": "Syllabus",
    "section": "Important sites to bookmark",
    "text": "Important sites to bookmark\n\nR Datahub\nAll coding in this class will be done in R. You may download the desktop version of RStudio if you wish, but it might be easier to use the datahub. It is up to you. Just make sure you have the latest version of R and RStudio, if you would like to download it to your laptop.\n\n\nBcourses\nImportant coursewide announcements will be sent out on bcourses.\n\n\nEd Discussion\nI have created a Ed discussion page for this course, which you can access through the link in bCourses (so you will be logged in). This is an online forum to ask questions to fellow students and answer other students’ questions. The GSIs and I will have access to the forum and may endorse or occasionally answer questions but this is primarily a forum for students to help each other – if you need an instructor or GSI’s assistance please attend office hours. Extra credit of up to 0.5% on the final course score will be awarded to the five students who have responded to the most questions on Ed by the end of the semester (with reasonable attempts at answering the questions).\n\n\nCBTF\nThis semester, you will be taking your quizzes in the Computer-Based Testing Facility in Sutardja Dai Hall. In order to take the test, you will have to log into the course site using your Calnet ID. I will post a practice quiz so that you can get the hang of how to do the scheduling etc. Meanwhile, take a look at the page “CBTF Getting Started for Students”.\n\n\nGradescope\nHomework assignments, take-home exams, and regrade requests (see Policies section below) will be submitted through Gradescope, which you can also access through the link in bCourses (you should not add yourself to Gradescope, as the roster has already been uploaded). You can view your grades here, as I will not be creating assignments on bCourses.\n\n\nFlextensions\nYou can request extensions of up to two days for up to two homework assignments, using this page, once assignments have been posted on Gradescope. You must make the request before the due date. If you have DSP accommodations, please send us a private message on Ed.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#academic-honesty-policy",
    "href": "syllabus.html#academic-honesty-policy",
    "title": "Syllabus",
    "section": "Academic Honesty Policy",
    "text": "Academic Honesty Policy\nThe student community at UC Berkeley has adopted the following Honor Code: “As a member of the UC Berkeley community, I act with honesty, integrity, and respect for others.”.\nMy expectation is that you will adhere to this code. Beyond the importance of respecting your fellow students, acting with integrity in completing course assignments helps ensure that they achieve their purpose, which is to help you learn and develop valuable statistical understanding and skills. Homework must be done independently. If you get stuck or want to explore alternative approaches, feel free to discuss issues with students or course staff at the homework parties or on Ed. You may ask an AI tool for help understanding a concept, or figuring out a coding error (but note that the answers are not always correct), but putting assignment questions into an AI tool and then copying and pasting/paraphrasing the answers will be considered plagiarism. It is also completely negates the purpose of the homework, which is to cement and internalize concepts from the course. It will not serve you for the exam either, when you have to tackle the problems on your own. I leave it to you to decide how much you would like to use genAI tools, but please use them with caution.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#emailed-policy",
    "href": "syllabus.html#emailed-policy",
    "title": "Syllabus",
    "section": "Email/Ed policy",
    "text": "Email/Ed policy\nIf you have a question for us, the fastest way to get a response is to post the question on Ed. If it deals with private matters, please make it a private post. If you are not comfortable writing a private post, come and see me. You can drop into office hours or make an appointment, either is fine.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#inclusivity-and-accommodation",
    "href": "syllabus.html#inclusivity-and-accommodation",
    "title": "Syllabus",
    "section": "Inclusivity and Accommodation",
    "text": "Inclusivity and Accommodation\nMy hope is to establish a learning environment in this course that welcomes diversity of thought, perspective, and experience, and to be respectful of your individual identity as a student. I am happy to use your preferred name and/or personal pronoun. If you feel uncomfortable as a result of anything that is said in class, or if you feel that your performance in the course is being impacted by experiences outside of class, please do not hesitate to reach out to me about your concerns. If you are uncomfortable being called on during class, just let me know.\nIn addition, if you need accommodations for any physical, psychological, or learning disability, please speak to me after class or during office hours. Please note that you must make arrangements in a timely manner through DSP so that I can make the appropriate accommodations.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#possibility-of-revisions-to-course-policies",
    "href": "syllabus.html#possibility-of-revisions-to-course-policies",
    "title": "Syllabus",
    "section": "Possibility of revisions to course policies",
    "text": "Possibility of revisions to course policies\nAll course policies, including assessment, are subject to change during the course of the semester in response to unforeseen events including, but not limited to, campus shutdowns due to various reasons, power outages, forest fires, and medical emergencies among members of the course staff.",
    "crumbs": [
      "Syllabus"
    ]
  }
]